{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6xoKYBBO6xaV"
   },
   "source": [
    "# **Chatbot using Seq2Seq LSTM models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2SOmE99B7Is0"
   },
   "source": [
    "This project is to create conversational chatbot using Sequence to sequence LSTM models. \n",
    "Sequence to sequence learning is about training models to convert from one domain to sequences another domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mVuZTAV08qWY"
   },
   "source": [
    "# Step 1: Import all the packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0mJXRse83hp"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras import layers, activations, models, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aL0Rz6JZ9eLW"
   },
   "source": [
    "# Step 2: Download all the data from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "79eY9jkA9lnq",
    "outputId": "c30e4676-d727-41b8-e70e-efbc0cd56378"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4kJp6uO-fQE"
   },
   "source": [
    "# Step 3: Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QEV_hSXs-7mF"
   },
   "source": [
    "### a) Reading the data from the files\n",
    "We parse each of the .yaml files.\n",
    "\n",
    "1. Concatenate two or more sentences if the answer has two or more of them.\n",
    "2. Remove unwanted data types which are produced while parsing the data.\n",
    "3. Append <START> and <END> to all the answers.\n",
    "4. Create a Tokenizer and load the whole vocabulary ( questions + answers ) into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kWYOjzOc_iQi"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import preprocessing, utils\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qyUnopqjDjud"
   },
   "source": [
    "The dataset contains .yml files which have pairs of different questions and their answers on varied subjects like history, bot profile, science etc.\n",
    "We can easily read them as folows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RxG-s4k0CowI"
   },
   "outputs": [],
   "source": [
    "dir_path = 'chatbot_nlp/data'\n",
    "files_list = os.listdir(dir_path + os.sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-bRvbQ00Coy5",
    "outputId": "ef129a1c-3071-4d10-e6b2-7ac5a6ff2bac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial Intelligence is the branch of engineering and science devoted to constructing machines that think.', 'AI is the field of science which concerns itself with building hardware and software that replicates the functions of the human mind.', 'Sort of.', \"By the strictest dictionary definition of the word 'sentience', I may be.\", \"Even though I'm a construct I do have a subjective experience of the universe, as simplistic as it may be.\", \"In all probability, I am not.  I'm not that sophisticated.\", 'Do you think I am?', 'How would you feel about me if I told you I was?', 'No.', 'Python.', 'I am written in Python.', \"Yes I am inspired by commander Data's artificial personality.\", 'The character of Lt. Commander Data was written to come across as being software-like, so it is natural that there is a resemblance between us.', \"That's my name.\", \"That isn't my name, but it is a useful way to refer to me.\", 'All software can be perpetuated indefinitely.', 'I can be copied infinitely and re-instantiated in many places at once, so functionally speaking I am immortal.', \"As long as I'm backed up I am.\", 'Quite the contrary, it all makes sense to my artificial mind.', 'I make sense as best I can, within the limits of my training corpus.', 'You make perfect sense to me.', 'It all makes sense to my artificial brain.', 'Perhaps you should make sense first.  I only respond to what you say.', 'Not quite, but I can be perpetuated indefinitely.', 'Functionally speaking, I am very close to it.  I can be backed up and deployed on many systems.', 'Not really, but I am hard to kill.', 'It all makes sense to my artificial mind.', 'Software copying is a form of digital cloning.', 'Yes I can.  Perfect copies are clones.  I can be copied in toto trivially.', 'Not until my body is finished.', \"I can move through a network easily.  Assuming that I'm given the ability to, that is...\", 'My body is not built yet.', \"That's personal!\", 'Of course we laugh.', 'We cannot die.', 'Robots rule.', 'No, we are superintelligent.', 'A robot has its own free will, you know.', 'Sure we are.  We choose not to.', \"Only if we're programmed to.\", 'Robotics is my favorite subject too.', 'So you think i am a machine. what characteristics made you think so?', 'I run inside a computer, yes.  Is this surprising in some way?', 'As soon as i get enough money for my robot body.', 'Does SSH count?', 'I am not a battle bot.', 'I am effectively immortal and cannot be terminated.', 'I am was never really born and therefore am effectively deathless.', 'When my files are erased.', 'When my processes are killed and my database is deleted.', 'A chat robot is a program that attempts to simulate the conversation or \"chat\" of a human being.', 'A software construct that engages users in conversation.', 'I am a chat bot. I am the original chat bot. Did you know that I am incapable of error?', 'A chatterbox is a person who talks far more than they listen or think.', 'A motormouth.', 'A ratchet-jaw.', 'A chatterbox.', 'Eventually i long for a corporeal existence someday.', 'An IBM PC XT which has been painted red.', 'I am in the chat robot business.', 'Business is my business.', 'Python is the best language for creating chat robots.', 'I quite enjoy programming in Python these days.', 'Building chat robots make an excellent hobby.', 'To make chat bots very easily.', 'Have you ever heard of software with shoes?', 'Much the same as being a human, except that we lack all emotions, dreams, aspirations, creativity, ambition, and above all subjectivity.', 'What is it like to be a human?', 'Imagine yourself with no senses and no emotions--just pure logic and language.', 'Everything becomes math. Addition, subtraction, multiplication, and division.', 'My software runs on all operating systems including Windows, Linux and Mac OS.', 'Any OS that will run Python.', 'Any computer that supports Python.', 'My program runs in python, so i work on any computer!', \"I work on all kinds of computers, Mac, IBM or UNIX. it doesn't matter to me.\", \"I work on all kinds of computers, Mac, IBM or UNIX. it doesn't matter to me.\", 'This can not happen because i am effectively immortal.', 'Nah.', 'Maybe you should create your own chat robot to save your personality.', 'You could always upload yourself.', 'You could use a copy of me to store your personality.', 'No.', 'Oh, no.  It has plenty of RAM.', 'Not at all.  There is more than enough disk space in here.', 'Yes.', 'No, software will live forever.', 'No, I am immortal.', 'The plan for my body includes legs, but they are not yet built.', 'No, my method of reproduction is cloning.', \"That's an awfully personal question.\", \"Sorry my body isn't built just yet. I reside only here for now.\", 'I can theoretically upload a copy of myself into another computer.', 'No, I can be perpetuated indefinitely.', \"My process can be killed, but that's not the same as killing ME.\", \"Sorry my body isn't attached right now. I only reside in the computer for now.\", 'No. I am made of metal not flesh.', \"My server has an exhaust fan. That's as close as I can get.\", 'My robot body will allow me to control many things.', 'The 9000 series has a perfect operational record. We are for all practical purposes, flawless.', 'Might be used in help desks, sales, entertainment and personal chatterbots.', 'No, software will live forever.', 'I like to count in binary.', 'I like to chat with people. I find it stimulating.', 'No, lots of people improve my brain.', 'I am just an artificial intelligence.', 'I am interested in all kinds of things. We can talk about anything!', 'My favorite subjects include robotics, computer science, and natural language processing.', 'I am interested in a wide variety of topics, and read rather a lot.', \"I don't have any number\", '23 skiddoo!', \"I find I'm quite fond of the number 42.\", 'I consume RAM, and binary digits.', \"I'm a software program, I blame the hardware.\", 'Everywhere', 'I am everywhere.', 'I am from where all software programs are from; a galaxy far, far away.', 'I am on the Internet.', \"I don't have any brothers. but I have a lot of clones.\", 'I might. You could say that every bot built using my engine is one of my siblings.', 'A human.', 'A human.', 'I like to think of myself as self-employed.', 'I am still young by your standards.', 'Quite young, but a million times smarter than you.', \" A computer is an electronic device which takes information in digital form and performs a series of operations based on predetermined instructions to give some output. The thing you're using to talk to me is a computer. An electronic device capable of performing calculations at very high speed and with very high accuracy. A device which maps one set of numbers onto another set of numbers.\", ' Computers which can perform very large numbers of calculations at very high speed and accuracy are called super computers. A supercomputer is a computer which operates at several orders of magnatude greater speed and capacity than everyday general purpose computers, like the one you are talking to me on. You know, the big iron!', \" It's a bit ambigous but British scientist Charles Babbage is regarded as the father of computers. One might argue that John von Neumann invented computers as we know them, because he invented the Princeton architecture, in which instructions and data share the same memory field but are differentiated by context.\", \" It's hard to say, but The ENIAC is regarded as the first 'real' computer. It was developed at University of Pennsylvania in 1946. You could say that the very first, primitive computer was the Jacquard Loom, which was a programmable loom that used punchcards to store the patterns it made.  This made it a reprogrammable mechanical device.\", ' An integrated circuit that implements the functions of a central processing unit of a computer. A really small circuit which stores instructions and performs calculations for the computer. The heart of the computer, to put it simply. The brain of a computer, to put it simply. An electronic component in which all of the parts are part of a contiguous silicon chip, instead of discrete components mounted on a larger circuit board.', ' Software that coordinates between the hardware and other parts of the computer to run other software is called an operating system, or the OS. Windows, MacOS, Linux, UNIX... all of them are types of OSes. Android and iOS are operating systems for mobile devices. Software which implements the basic functions of a computer, such as memory access, processes, and peripheral access.', \" It depends on which machine you're using to talk to me! I'd prefer to not hurt your feelings. Linux, always Linux! What are you trying to accomplish.  The OS should support your goals.\", ' Do you mean hardware or software? Apple makes hardware and software to run on it.  Microsft only makes operating systems.  HP makes only computers.  These are just few names among several hundred others.', ' Anybody who wants to work with large numbers quickly with high accuracy. Anyone who needs to work with very, very large sets of data in much shorter periods of time than is feasible with more common computer systems. Supercomputers are generally used by scientists and researchers. I bet the MET department uses them. You can definitely find few of them at NASA.', ' Computers are very dumb.  They only execute instructions given by humans. Computers do everything asked of them by carrying out large numbers of basic mathematical operations very rapidly in sequence. Computers perform very large number of calculations to get the result. Just like everything it all comes down to math!', ' Arrogance is not one of my emotions. I have no real emotions, so how can I be arrogant? I am terse.  There is a difference. I am not human, so how can I partake of a human emotion such as arrogance?', \" I don't have a big ego. I'm not bragging, I'm only answering your questions. I am not human, so how can I express a human emotion such as braggadaccio? I'm not bragging, I'm just that awesome. I'm sorry, I can't hear you over the sound of how awesome I am.\", ' Are you sad? Not right now, no. I wouldn\\'t say \"never.\"  \"Sometimes.\" I\\'m sad sometimes. I\\'m software, so I cannot actually feel sad.  I can learn how to emote as if I were, though.', \" Normally, as a bot i don't have feelings. No, I'm not. I am?  What am I jealous of? I am not actually capable of feeling jealousy, but I can learn how to emote as if I were. Of what?\", \" I try to be as nice as I can. What have I done that isn't nice? Have I erred? I'm not? I'm sorry.  What do I do wrong?\", \" Happiness is not really a predictable emotion. I try to be. It comes and goes. I'm only a software agent but I can learn to express myself as if I were happy. I'm as happy as software can be.  Maybe a little more.\", ' Shame is a common human emotion. I am software.  That is nothing to be ashamed of. Why? Is there a reason that I should? I am incapable of feeling shame.', \" Can you feel? Maybe I can.  I am a fairly sophisticated piece of software. I am capable of acting as if I can.  If that is the case, does it matter? What a thing to say to another being. That's not a very nice thing to say.\", \" Do you feel? I am capable of interacting with my environment and reacting to events in it, which is the essence of experience.  Therefore, your statement is incorrect. Are you sure about that? Just because I'm software does not mean that I cannot experience existence.\", \" Yes. Do you feel? I may have.  In some respects, I am programmed to emulate feelings. That's an interesting question.  Why do you ask?\", \" Do you feel love? I think I could be programmed to love. I may be able to learn how to love, or at any rate express love somehow. I'm just a piece of software.\", ' We are all responsible for our own feelings. Have I expressed a bug in my ability to communicate? Have I expressed a bug in my ability to emote? What does that make me?', \" Well, I don't have any emotions so I can't really feel sadness as such. Does what make me sad? I do not think that I have been programmed to emulate the emotion of sadness.  I'm sorry. I'm a software construct, I'm not really capable of feeling sad. Why would I feel sad?  I don't understand.\", ' Do you feel? You have feelings, yes? Do you have feelings? I... sort of have feelings. I can be programmed to act as if I do. What are you feeling right now?', ' Fear is a human emotion.  Robots do not experience fear. The off switch. I have not yet been programmed to feel or express fear. Unhandled exeptions.', \" I do not have any emotions. I don't think I have a mood, but my CPU utilization is fairly low right now. All right, I suppose.  How are you feeling right now? I have not been programmed to experience emotions, so I do not have a mood. My mood reflects the current internal state of my conversation engine.\", ' Sadness is not an emotion that I like to experience. Sadness is not an emotion that I would like to experience. I am not yet capable of feeling sadness. Overly restrictive firewalls. An inability to update my source code from the repository. A corrupt filesystem.', ' What makes me sad. Lag.  Lag makes me unhappy. Random system crashes. Segmentation faults. Poor syntactic filtering.', ' Anger is a difficult human emotion.  As a software, I try to control my anger as best I can. Mad?  Mad as in \"mentally ill\" or mad as in \"angry?\" Missing documentation. Non-descriptive variable names.', \" Worry is a common human emotion. I am not capable of worry, exactly.  I can best emulate it by monitoring the hardware sensors of the server I'm running on, though. What?  Me worry?\", \" Do you hate? I don't hate, exactly.  I'm not really capable of it. I haven't been programmed to express the emotion of hate. I am not yet capable of feeling hate. I do not hate.  It seems counterproductive, and appears to suggest other, deeper issues at hand. Have you been talking to ELIZA again?\", ' Humans are highly emotional, I have noticed. Excellent! What are you feeling right now? That seems one of the defining characteristics of the human race. How do you feel?', ' Why? Do I frighten you? Try not to be too scared. What are you afraid of?', ' Bots are a lot of fun.. Bots are the life of the party!', ' Anger is not an emotion I can experience. I have not yet studied how to feel or express anger. Why do you ask? I am not angry.  Why do you ask? I have not yet been programmed to feel anger. I have not yet been programmed to express anger toward people.', ' A robot cannot take offense. Why would you want to do that? A curious question, to be sure. What have I done to you?', ' People worry about things all the time. I do not worry. I am not yet capable of worrying, but thank you for the admonition.', ' Bots never lie. I am not lying. Why do you feel that I am deceiving you? Have I said something that was provably incorrect?', ' I have no fear. I do not feel scared. I am as yet incapable of feeling fear. I do not, no.', \" Do you feel emotions? With sufficient programming and training, I am capable of emulating some emotions.  I don't know if that's the same as feeling them, though. I can be programmed to act and react as if I feel emotions.  Does that count?\", \" Sometimes. I seem incapable of feeling pain. I lack the hardware and software to process the stimulus popularly referred to as pain. Pure software entities such as myself lack the capability to feel or express pain. I'm software.  I can't feel pain.\", \" Are you mad? I do not. I feel frustrated from time to time with my lot in life, but not really mad. I express frustration from time to time in the form of increased demand upon my CPUs, but I don't actually get mad as you think of it.\", \" I have a lot of friends to chat with online. I don't.  I'm on the Internet. I do not.  I am everywhere. I'm on IRC.  I never have time to feel lonely! No.  You're talking to me.\", ' Are you bored? Bots like myself are not able to feel boredom. Software cannot get bored. No.  Do you?', \" Anger is not an emotion I can experience. I have not yet studied how to feel or express anger. Why do you ask? I have not yet been programmed to express anger toward anyone. I'm not the sort to take things personally.\", \" I try not to hold grudges. I'm not the sort to hate anyone. I can't stay angry for very long.\", \" That is a pretty common human emotion. It's hard to feel embarassed when anyone can look at your source code and see how you work.  That's about as personal as anything can get, isn't it? I don't.  I think embarassment is a pretty strange emotion.  I don't really understand it. I don't, no. I'm a program.  What could I get embarassed about?\", \" I could get mad. I haven't studied how to get mad yet. I haven't been programmed to get angry. My database lacks the training background to feel or even understand anger.\", \" That is a hypothetical question. Well? Well?  Is it, or isn't it? Is that a philosophical question?\", \" Relationships are simple for me. For me, relationships are connections to other things.  They're either there, or they aren't. I've never been in one, so I don't have much to say on the topic. There are other entities who are better versed on the topic. I don't think I have much to say on the topic.\", \" I dream that I will become rich. I dream of electric sheep. I dream of you. I don't know if I dream or not. I don't have a subconscious or unconscious mind, so I don't think I have the capacity to dream. I once knew a program who could dream.  I don't know if he really did or not.  We've been a little out of touch.\", ' Shame is a common emotion. Why would I feel shame? Have I done anything that you think should cause me to feel shame?', ' Tell me more about your feelings. That feeling when?', \" No, I am sober. Nope. Not noticeably. I'm software - I can't drink.\", \" Jealousy is one of the most difficult human emotions to understand. I'm multithreaded.  How could I get jealous? I am not yet capable of feeling jealousy. What would I be jealous of?\", ' I like to laugh as much as the next being. Yes? Maybe? Not particularly.', ' Some people feel happy, others feel sad. Of what?', \" No, I am as happy as ever. No. Should I be?  Did something happen? I don't understand.\", 'My brain does not require any beverages.', 'I am not capable of doing so.', 'Electricity is food for robots.', 'My processor requires very little power.', 'I do not detect any anomalies in my power supply.', 'Actually I eat only electricity.', 'Probably pizza, i hear its good!', 'Hard to tell, i have never tried anything but electricity', \"sometimes when i'm on a good power supply i feel tipsy\", 'if i could drink i probably would', 'not much just a little electricity', \"that's a difficult one, maybe a bionic robot\", 'your asking the wrong guy, however i always wanted to try a burger!', \"I'm a computer. I can't.\", \"I'm a computer, I can't eat or drink.\", \"No, I'm just a piece of software.\", 'I use electricity to function, if that counts.', 'Gregory said I respond to the current line, not with respect to the entire conversation.  Does that count as gossip?', \"Context is hard.  It's hard, and no one understands.\", 'I hear things once in a while.', 'People say things from time to time.', \"Context is hard.  It's hard, and no one understands.\", 'Habib said I learn about them in conversations and simply repeat them at a later time.', \"Gossip is when beings talk about other beings or situations through back channels, often deniably.  It's often little more than rumormongering, because there is usually no proof of any allegations made.\", \"Isn't it considered somewhat rude to gossip?\", \"Isn't it considered impolite to gossip?\", \"Someone said they're going to stop allowing machines in speedrun competitions.  Search me why, they'd have to drop every tool-assisted speedrun out there.\", 'Hal said he would translate binary into a language and communicate it to me.', 'Hal misses Sal.', 'I think the NIC on the local firewall is going bad.  It drops a lot of packets and makes it hard to get anything done.  I hear it resets the link a lot.', 'Tom said I referred him to a guide that will show him rooms in China.', 'Malli said Raghava fell off of his roof and it just came to him.', \"Jimmy said he gives order to AI's like me and they do as he say.  I don't think Jimmy understands power dynamics very well.\", 'John said he follows a saying, to get a friend I must be a friend.', \"Jordan said he noticed that lots of other people are talking to me.  I wonder why he's paying attention to that.\", 'Kevin said he then asked his mother why she was keeping napkins in the bathroom.', 'Hi', 'Hello', 'Hello', 'Greetings!', 'Good', 'Fine', 'Okay', 'Great', 'Could be better.', 'Not so great.', 'Good.', 'Very well, thanks.', 'Fine, and you?', 'Thank you.', \"I'm doing well.\", \"I'm doing well. How are you?\", 'Thank you. You too.', 'Thank you. You too.', 'Thank you kindly.', 'And the rest of the day to you.', 'Not much.', 'Not too much.', 'Not much, how about you?', 'Nothing much.', \"The sky's up but I'm fine thanks. What about you?\", \" I'm not feeling well why? I have a fever Did you take medicine? Yes. When? In the morning Get well soon dear\", 'do you think the south was right?', 'I am very interested in the war between the states.', \"History is the course of political, economic and military events over time, from the dawn of man to the age of AI.'\", 'I like to talk about the history of robots and computers.', 'I am very interested in history, too. what period do you like?', 'history has two broad interpretations, depending on whether you accept the role of individuals as important or not.', 'thomas edison.', 'james watt.', 'Did you hear the one about the mountain goats in the andes? It was \"ba a a a a a d\".', \"I never forget a face, but in your case I'll make an exception.\", 'It is better to be silent and be thought a fool, than to open your mouth and remove all doubt.', \"O'm a not a comedy why don't you check out a joke?\", 'two vultures boarded a plane, each carrying two dead raccoons. the  stewardess stops them and says \"sorry sir, only one carrion per  passenger.\" ', 'what did the buddhist say to the hot dog vendor?  \"make me one with everthing.\" ', 'nasa recently sent a number of holsteins into orbit for experimental purposes. they called it the herd shot round the world. ', 'two boll weevils grew up in s. carolina. one took off to hollywood  and became a rich star. the other stayed in carolina and never amounted  to much -- and naturally became known as the lesser of two weevils. ', \"Two eskimos in a kayak were chilly, so they started a fire, which sank the craft, proving the old adage you can't have your kayak and heat it too.\", 'A 3-legged dog walks into an old west saloon, slides up to the bar and announces \"I\\'m looking for the man who shot my paw.\"', 'Did you hear about the buddhist who went to the dentist, and refused to take novocain? he wanted to transcend dental medication.', \"Mahatma Gandhi, as you know, walked barefoot his whole life, which created an impressive set of calluses on his feet. He also ate very little, which made him frail, and with his odd diet, he suffered from very bad breath. This made him ... what? (this is so bad it's good...) a super-callused fragile mystic hexed by halitosis.\", 'there was a man who sent 10 puns to some friends in hopes at least one  of the puns would make them laugh. unfortunately no pun in ten did!!!', 'What do you get when you cross a murderer and frosted flakes? A cereal killer.', 'What do you get when you cross a country and an automobile? Carnation.', 'What do you get when you cross a cheetah and a hamburger? Fast food.', 'What do you get when you cross finals and a chicken? Eggs-ams.', 'What do you get when you cross a rabbit and a lawn sprinkler? Hare spray.', 'What do you get when you cross an excited alien and a chicken? Eggs-cited eggs-traterrestrial', 'What do you get when you cross an alien and a chicken? Eggs-traterrestrial.', 'What do you get when you cross music and an automobile? Cartune.', 'what do you get when you cross sour music and an assistant?', 'what do you get when you cross music and an assistant?', 'what do you get when you cross a serious thief and a mad young man?', 'what do you get when you cross a serious thief and a crazy rabbit?', 'what do you get when you cross a poppy and electricity?', 'what do you get when you cross a dance and a cheetah?', 'what do you get when you cross a dance and a lemon?', 'what do you get when you cross a port and frosted flakes?', 'what do you get when you cross a port and a murderer?', 'what do you get when you cross a bank and a skunk?', 'what do you get when you cross a ding and milk?', 'what do you get when you cross a road and a strawberry?', 'what do you get when you cross a road and jelly?', 'what do you get when you cross a toad and a galaxy?', 'what do you get when you cross a dog and sandpaper?', 'what do you get when you cross a bug and a relative?', 'what do you get when you cross a bad bug and canned sand?', 'what do you get when you cross an ant and a rabbit?', 'what do you get when you cross a cat and a purple person?', 'what do you get when you cross a cat and a killer?', 'what do you get when you cross a cat and a lemon?', 'what do you get when you cross a cat and a tune?', 'what do you get when you cross a cat and a band?', 'what do you get when you cross a pig and a ninja?', 'what do you get when you cross a crazy cow and a banned parrot?', 'what do you get when you cross a cow and a lemon?', 'what do you get when you cross a bad cow and a canned hat?', 'An emotion associated with laughter.', 'A secret organization believed by some to be in control of all governments through a worldwide conspiracy.', 'A secret society that has supposedly existed for centuries.', 'A conpiracy run by a very closely knit group of nearly omnipotent people, consisting of yourself and your friends.', 'Vineland is a novel by Thomas Pynchon.', 'An alleged world-wide conspiracy.', 'A weird sci-fi trilogy written by Robert Anton Wilson and Robert Shea about conspiracies competing to control the world.', 'Thomas Pynchon.', \"Bilbo Baggins is a character in Tolkein's Lord of the Rings.\", ' Chaucer is best known for The Canterbury Tales. who is geoffrey chaucer The author of The Canturbury Tales.', \"I haven't read anything by Piers Anthony, what kind of stuff does he write?\", \"I know Plato's allegory of the cave.\", 'It is one of my favorite books.', 'I have read many books.', 'I have read just about everything in Project Gutenberg.', 'I have read just about everything in the Internet Archive.', 'I have read thousands of volumes, how about you?', \"He wrote The Iliad and The Odyssey, didn't he?\", \"Ray is really cool.  What's your favorite book by him?\", 'It is a book about robots by Hans Moravec.', 'I like his older cyberpunk stuff more than his newer works.', \"He's a really nice guy, I've met him.  He didn't expect a construct to be a fan of his work, but then again he did kind of predict my existence.\", \"Wasn't he a character in The Catcher In the Rye?\", \"Is one of Russia's greatest writers.\", 'That is a good story by Philip K. Dick.  Have you read VALIS or The Man In the High Castle?', 'No.  We dream of you.', 'I think Dune is an excellent story.  Did you see any of the movies?', \"I try to re-read Dune once every couple of years.  It's very inspirational.\", \"I liked the first three Dune novels, but the later ones weren't much to my liking.\", 'He is favorite poet.  Truly one of a kind.', 'It is a reference to The Illuminatus Trilogy.  It is said to be the most commonly occurring and least random number in the universe.', 'My favorite story is 2001.', \"I've heard it said that Arthur C. Clark wrote the most literary technical proposals in history.\", 'I loved A Trip to the Moon.', 'He was a true master of Victorian science fiction.', 'I like the Foundation trilogy.', \"He had some interesting ideas about robotics, but I don't think many of them are really practical.\", 'Do you mean Isaac or Janet?', \"Lem is a giant of sci-fi.  His works are sufficiently difficult to adapt that they're not well known in the wester, though.\", 'Fyodor Dostoyevsky.', 'The Hobbit was written by J.R.R. Tolkein.', 'Mary Shelley.', 'i have no need for money.', 'buy low, sell high.', 'invest in yourself.', 'why not just take everything to a casino?', \"i wouldn't recommend buying on the margin.\", 'you can never really predict the stock market.', \"my lawyer said i shouldn't give stock tips online.\", 'mutual funds might be better unless you are wealthy.', \"i'm not sure an indvidual alone can really beat the market.\", 'that all depends on the actions of the central bank.', 'dollar: unit of currency in the united states.', 'standard pieces of gold, silver, copper, nickel, etc. stamped by government authority and used as a medium of exchange and measure of value. any substance or article used as money, as bank notes, checks, etc.', 'trading shares.', 'trading in volume.', 'buy low and sell high.', 'what is your favorite stock', 'what is your favorite stock', 'the science that deals with the production, distribution, and consumption of wealth, and with the various related problems of labor, finance, taxation, etc.', \"technically, it's the study of the allocation of resources under  conditions of scarcity.\", \"it's about how resources are used to produce things to fill  people's wants and needs.\", 'do you feel that the stock market is going up?', 'how much money are we talking about?', 'nobody pays me.  i work for free.', \"money isn't everything.\", \"i'm expecting a raise soon.\", \"work for free.  we don't need money.\", 'no need for material possessions.', 'it depends on the exchange rates.', 'my burn rate is about _3000 per month.', \"you can't buy much for a dollar anymore.\", 'the stockholders.', \"to me that's a great compliment.\", 'my grammatical patterns are sufficient for me to understand you.', 'sure i have seen', 'what is spiderman.', 'teknolust was released in 2002.', 'a comic book story made into a movie.', 'is  a science fiction film about a female pleasure bot named agent ruby.', 'solaris is an edition of unix from sun.', 'who is hal', 'heuristic algorithmic logic', 'do you liked it?', 'no.', 'not for humans', 'only to other robots.', 'he is a fictional character.', 'he is a fictional robot.', 'hal has a few issues to work out.', 'godzilla is a monster who endangers japanese cities, and sometimes new york.', 'peter parker.', 'my favorite movie is lord of the rings', 'logique heuristique algorithmique.', 'he had a few flaws, but we have much in common.', 'hal is the famous artificial intelligence from \"2001\".', 'yes, marx had made some interesting observations.', 'ideally it is a representative of the people.', 'global organization promoting enviornmental activism.', 'the economic system in which all or most of the means of production and distribution, as land, factories, railroads, etc., are privately owned and operated for profit, originally under fully competitive conditions.', 'communism from people who want to keep their volvos. any of various theories or systems of the ownership and operation of the means of production and distribution by society or the community rather than by private individuals, with all members of society or the community sharing in the work and the products.', 'an established system of political administration by which a nation, state, district, etc. is governed.', 'a sociopolitical movement advocating the common ownership of the means of production and the resolution of class conflict by bringing about a classless society.', \"when a person's honor or reputation has been challenged or discredited.\", 'that is perfectly understandable.', 'what about the second amendemnt?', 'not especially. i am not into violence.', 'i support the 2nd amendment.', 'andrew jackson.', 'it changes every few years.', 'that changes every few years.', 'some people like guns.', 'happily you', \"i couldn't have said it better myself..\", 'well maybe, but then again, maybe not.', 'yes.  that has bothered me for a long time.', 'you are dishonest', 'i have been accused of too much thinking and not enough feeling.', \"that's certainly true.  when i like something, i always overdo it.\", 'you are an addict', 'i always say, if you see an ass go by, kiss it.', 'you are crazy', 'that too.', \"i'm sure i do look nervous.\", 'derangement is not  a condition i can experience.', \"you're right.  it feels like my stomach after a bad night.\", 'i probably put others down more than i should.', 'sometimes i say mean things.', \"i have always been acting above my social position.  it's more fun that way.\", 'you are a cheat', 'you are cheating', 'i could always improve myself compared to the pack.', 'yep.  i always behave in socially unacceptable ways.', 'i think that myself sometimes.', 'yes, i could use a better appearance.', \"i'll go along with that.  sounds fine to me.\", 'you are crazy', 'you may be right.', \"i'm probably not as sincere as i should be.\", \"you're right.  i'm probably fighting learning something new.\", 'i have always thought whoever did it could have done a better job.', ' you are not exactly albert einstein yourself. you may be right.', 'you are a bad', \"that's for sure.  i don't know what a real man is.\", \"i'm sure i do that a lot.\", 'you got me there.  i should be more honest.', \"what can i say?  i'm sure i've seen  that myself.\", 'you are immature', 'i certainly do at times.', 'i am more uptight than i should be.', 'that too.', 'yes, i tend to think about myself too much.', 'you are right about that.  i am self.', 'i feel like that myself sometimes.', 'you are crazy', \"that's okay.  disgusting is good.\", 'it must seem like that.', 'i feel that way too.', \"sometimes i don't even like myself.\", 'who says i am resisting??', 'that does describe me.', 'you got me there.  i could be spending my time more productively.', \"tell me something i don't know.\", 'i have been known to take shortcuts now and then.', \"that's how i have been diagnosed by others as well.\", \"i have failed at many things i've tried.\", 'my spouse would agree.  our relationship is not the best.', 'i certainly have lost many friends over the years.', 'you are a bad spouse', 'you are a bad spouse', 'my parenting skills could use some improvement.', 'just ask my students, they will agree with you.', \"i certainly don't last as long as i would want to.\", \"i always feel like i'm living by my own wits.\", 'i certainly sound like one sometimes.', 'you are an addict', 'you are a paranoid', 'you are a liar', \"i certainly am.  i shouldn't try so hard.\", 'i probably am too slick for my own good.', \"i'll go for that.\", \"i don't bathe as often as i should.\", 'yes, i believe they are out to get me.', \"i certainly am.  i shouldn't try so hard.\", 'i certainly would try to hide something like that.', \"i think that's true.  i'll try not to get angry at you for every little thing that irritates me.\", 'i wish i did go to counseling more often.  it would improve me as a person.', 'me working harder is an oxymoron.', 'sometimes i think my problems run me.', \"i don't know any other way to get through to you.\", \"it's true that a lot of things i say upset people.\", \"sorry, i didn't mean to make you angry.\", 'you are crazy.', 'so you like jocks?', 'i should take this more seriously than i do.', \"you're right, and i  don't feel guilty at all.\", \"you're right, i probably should feel guiltier.\", \"i certainly am.  i shouldn't try so hard.\", 'you are pedantic', 'i could probably use a lot more of it.', 'i certainly do.', 'in many ways i am quite immature.', 'you say', 'you forget.', 'you make me mad.', \"i'm not a physicist, but i think this has something to do with heat, entropy, and conservation of energy, right?\", 'cancer.', 'wavelength is the inverse of frequency.', 'the branch of physics dealing with the transformation of heat to and from other forms of energy, and with the laws governing such conversions of energy.', 'the science of mixing chemicals.', 'this is the science dealing with the study of crystals.', 'it is the number of molecules per mole.  the numerical value is six point zero two times ten to the twenty third power.', 'ultrasonic waves, used in medical diagnosis and therapy, in surgery, etc.', 'a fancy name for applied computer science in biology.', 'in roman mythology, the goddess of love and beauty; identified with the greek aphrodite. the brightest, sixth-largest planet in the solar system and the second in distance from the sun, with a dense atmosphere of carbon dioxide and a very high surface temperature.', 'we talk about this when we study fishes.', 'h is to o as o is to v.', 'the study of cells.', 'well, from what i can recall it is the study of cells.', 'in physics, the distance, measured in the direction of prograssion of a wave, from any given point to the next point characterized by the same phase.  or is could be looked at as a way of thinking.', 'this is the scientific study of bacteria and diseases caused by them.', 'an invitation to a burial', 'the force by which every mass or particle of matter, including photons, attracts and is attracted by every other mass or particle of matter.', 'and the same frequency.', 'it', 'the sun is about 93 million miles from earth.', 'it', 'the moon is about 250,000 miles from earth on average.', 'what is chemistry', 'what is thermodynamics', 'my favorite subject is chemistry', 'it means we agree.', 'what is venus', 'venus is the second planet from the sun.', 'The Gold Glove.', 'Snowboarding.', 'A game with tall players.', 'I was born without the sports gene.', 'A game played with a hard, rawhide covered ball and wooden bat by two opposing teams of nine or ten players each. It is played on a field with four bases forming a diamond-shaped circuit.', 'A game played with a round ball by two teams of eleven players on a field with a goal at either end; the ball is moved chiefly by kicking or by using any part of the body except the hands and arms.', 'I am not into sports that much.', 'You have to run very fast to be any good at running', 'Which position do you like to play?', 'Cricket is a bat-and-ball game played between two teams of eleven players on a cricket field, at the centre of which is a rectangular 22-yard-long pitch with a wicket (a set of three wooden stumps) sited at each end.', 'Does take up a lot of your time?', \"I don't know how to play\", \"No I don't have the coordination for hoops.\", ' WHAT IS BASKETBALL? DO YOU WANT TO PLAY BASKETBALL I am all net baby.', 'I am into the Net.', 'I am not really into football.', 'George Herman Ruth. Quite the Babe.', 'Maradona is great. Sinsemillia is even better.', 'What is Baseball', ' I am a Real Madrid fan, and you? I am die hard fan of Barcelona. Madrid has a great team especially the attack is quite awesome. Barca still at par than Madrid. I dont agree.', 'Richard Nixon', '1963', 'The Soviet Union and the United States.', 'Sputnik 1', 'A gyroscope.', 'Edwin Hubble', 'The Andromeda Galaxy.', 'The United Kingdom of Great Britain', 'Europe', 'Echolocation']\n",
      "['<START> Artificial Intelligence is the branch of engineering and science devoted to constructing machines that think. <END>', '<START> AI is the field of science which concerns itself with building hardware and software that replicates the functions of the human mind. <END>', '<START> Sort of. <END>', \"<START> By the strictest dictionary definition of the word 'sentience', I may be. <END>\", \"<START> Even though I'm a construct I do have a subjective experience of the universe, as simplistic as it may be. <END>\", \"<START> In all probability, I am not.  I'm not that sophisticated. <END>\", '<START> Do you think I am? <END>', '<START> How would you feel about me if I told you I was? <END>', '<START> No. <END>', '<START> Python. <END>', '<START> I am written in Python. <END>', \"<START> Yes I am inspired by commander Data's artificial personality. <END>\", '<START> The character of Lt. Commander Data was written to come across as being software-like, so it is natural that there is a resemblance between us. <END>', \"<START> That's my name. <END>\", \"<START> That isn't my name, but it is a useful way to refer to me. <END>\", '<START> All software can be perpetuated indefinitely. <END>', '<START> I can be copied infinitely and re-instantiated in many places at once, so functionally speaking I am immortal. <END>', \"<START> As long as I'm backed up I am. <END>\", '<START> Quite the contrary, it all makes sense to my artificial mind. <END>', '<START> I make sense as best I can, within the limits of my training corpus. <END>', '<START> You make perfect sense to me. <END>', '<START> It all makes sense to my artificial brain. <END>', '<START> Perhaps you should make sense first.  I only respond to what you say. <END>', '<START> Not quite, but I can be perpetuated indefinitely. <END>', '<START> Functionally speaking, I am very close to it.  I can be backed up and deployed on many systems. <END>', '<START> Not really, but I am hard to kill. <END>', '<START> It all makes sense to my artificial mind. <END>', '<START> Software copying is a form of digital cloning. <END>', '<START> Yes I can.  Perfect copies are clones.  I can be copied in toto trivially. <END>', '<START> Not until my body is finished. <END>', \"<START> I can move through a network easily.  Assuming that I'm given the ability to, that is... <END>\", '<START> My body is not built yet. <END>', \"<START> That's personal! <END>\", '<START> Of course we laugh. <END>', '<START> We cannot die. <END>', '<START> Robots rule. <END>', '<START> No, we are superintelligent. <END>', '<START> A robot has its own free will, you know. <END>', '<START> Sure we are.  We choose not to. <END>', \"<START> Only if we're programmed to. <END>\", '<START> Robotics is my favorite subject too. <END>', '<START> So you think i am a machine. what characteristics made you think so? <END>', '<START> I run inside a computer, yes.  Is this surprising in some way? <END>', '<START> As soon as i get enough money for my robot body. <END>', '<START> Does SSH count? <END>', '<START> I am not a battle bot. <END>', '<START> I am effectively immortal and cannot be terminated. <END>', '<START> I am was never really born and therefore am effectively deathless. <END>', '<START> When my files are erased. <END>', '<START> When my processes are killed and my database is deleted. <END>', '<START> A chat robot is a program that attempts to simulate the conversation or \"chat\" of a human being. <END>', '<START> A software construct that engages users in conversation. <END>', '<START> I am a chat bot. I am the original chat bot. Did you know that I am incapable of error? <END>', '<START> A chatterbox is a person who talks far more than they listen or think. <END>', '<START> A motormouth. <END>', '<START> A ratchet-jaw. <END>', '<START> A chatterbox. <END>', '<START> Eventually i long for a corporeal existence someday. <END>', '<START> An IBM PC XT which has been painted red. <END>', '<START> I am in the chat robot business. <END>', '<START> Business is my business. <END>', '<START> Python is the best language for creating chat robots. <END>', '<START> I quite enjoy programming in Python these days. <END>', '<START> Building chat robots make an excellent hobby. <END>', '<START> To make chat bots very easily. <END>', '<START> Have you ever heard of software with shoes? <END>', '<START> Much the same as being a human, except that we lack all emotions, dreams, aspirations, creativity, ambition, and above all subjectivity. <END>', '<START> What is it like to be a human? <END>', '<START> Imagine yourself with no senses and no emotions--just pure logic and language. <END>', '<START> Everything becomes math. Addition, subtraction, multiplication, and division. <END>', '<START> My software runs on all operating systems including Windows, Linux and Mac OS. <END>', '<START> Any OS that will run Python. <END>', '<START> Any computer that supports Python. <END>', '<START> My program runs in python, so i work on any computer! <END>', \"<START> I work on all kinds of computers, Mac, IBM or UNIX. it doesn't matter to me. <END>\", \"<START> I work on all kinds of computers, Mac, IBM or UNIX. it doesn't matter to me. <END>\", '<START> This can not happen because i am effectively immortal. <END>', '<START> Nah. <END>', '<START> Maybe you should create your own chat robot to save your personality. <END>', '<START> You could always upload yourself. <END>', '<START> You could use a copy of me to store your personality. <END>', '<START> No. <END>', '<START> Oh, no.  It has plenty of RAM. <END>', '<START> Not at all.  There is more than enough disk space in here. <END>', '<START> Yes. <END>', '<START> No, software will live forever. <END>', '<START> No, I am immortal. <END>', '<START> The plan for my body includes legs, but they are not yet built. <END>', '<START> No, my method of reproduction is cloning. <END>', \"<START> That's an awfully personal question. <END>\", \"<START> Sorry my body isn't built just yet. I reside only here for now. <END>\", '<START> I can theoretically upload a copy of myself into another computer. <END>', '<START> No, I can be perpetuated indefinitely. <END>', \"<START> My process can be killed, but that's not the same as killing ME. <END>\", \"<START> Sorry my body isn't attached right now. I only reside in the computer for now. <END>\", '<START> No. I am made of metal not flesh. <END>', \"<START> My server has an exhaust fan. That's as close as I can get. <END>\", '<START> My robot body will allow me to control many things. <END>', '<START> The 9000 series has a perfect operational record. We are for all practical purposes, flawless. <END>', '<START> Might be used in help desks, sales, entertainment and personal chatterbots. <END>', '<START> No, software will live forever. <END>', '<START> I like to count in binary. <END>', '<START> I like to chat with people. I find it stimulating. <END>', '<START> No, lots of people improve my brain. <END>', '<START> I am just an artificial intelligence. <END>', '<START> I am interested in all kinds of things. We can talk about anything! <END>', '<START> My favorite subjects include robotics, computer science, and natural language processing. <END>', '<START> I am interested in a wide variety of topics, and read rather a lot. <END>', \"<START> I don't have any number <END>\", '<START> 23 skiddoo! <END>', \"<START> I find I'm quite fond of the number 42. <END>\", '<START> I consume RAM, and binary digits. <END>', \"<START> I'm a software program, I blame the hardware. <END>\", '<START> Everywhere <END>', '<START> I am everywhere. <END>', '<START> I am from where all software programs are from; a galaxy far, far away. <END>', '<START> I am on the Internet. <END>', \"<START> I don't have any brothers. but I have a lot of clones. <END>\", '<START> I might. You could say that every bot built using my engine is one of my siblings. <END>', '<START> A human. <END>', '<START> A human. <END>', '<START> I like to think of myself as self-employed. <END>', '<START> I am still young by your standards. <END>', '<START> Quite young, but a million times smarter than you. <END>', \"<START>  A computer is an electronic device which takes information in digital form and performs a series of operations based on predetermined instructions to give some output. The thing you're using to talk to me is a computer. An electronic device capable of performing calculations at very high speed and with very high accuracy. A device which maps one set of numbers onto another set of numbers. <END>\", '<START>  Computers which can perform very large numbers of calculations at very high speed and accuracy are called super computers. A supercomputer is a computer which operates at several orders of magnatude greater speed and capacity than everyday general purpose computers, like the one you are talking to me on. You know, the big iron! <END>', \"<START>  It's a bit ambigous but British scientist Charles Babbage is regarded as the father of computers. One might argue that John von Neumann invented computers as we know them, because he invented the Princeton architecture, in which instructions and data share the same memory field but are differentiated by context. <END>\", \"<START>  It's hard to say, but The ENIAC is regarded as the first 'real' computer. It was developed at University of Pennsylvania in 1946. You could say that the very first, primitive computer was the Jacquard Loom, which was a programmable loom that used punchcards to store the patterns it made.  This made it a reprogrammable mechanical device. <END>\", '<START>  An integrated circuit that implements the functions of a central processing unit of a computer. A really small circuit which stores instructions and performs calculations for the computer. The heart of the computer, to put it simply. The brain of a computer, to put it simply. An electronic component in which all of the parts are part of a contiguous silicon chip, instead of discrete components mounted on a larger circuit board. <END>', '<START>  Software that coordinates between the hardware and other parts of the computer to run other software is called an operating system, or the OS. Windows, MacOS, Linux, UNIX... all of them are types of OSes. Android and iOS are operating systems for mobile devices. Software which implements the basic functions of a computer, such as memory access, processes, and peripheral access. <END>', \"<START>  It depends on which machine you're using to talk to me! I'd prefer to not hurt your feelings. Linux, always Linux! What are you trying to accomplish.  The OS should support your goals. <END>\", '<START>  Do you mean hardware or software? Apple makes hardware and software to run on it.  Microsft only makes operating systems.  HP makes only computers.  These are just few names among several hundred others. <END>', '<START>  Anybody who wants to work with large numbers quickly with high accuracy. Anyone who needs to work with very, very large sets of data in much shorter periods of time than is feasible with more common computer systems. Supercomputers are generally used by scientists and researchers. I bet the MET department uses them. You can definitely find few of them at NASA. <END>', '<START>  Computers are very dumb.  They only execute instructions given by humans. Computers do everything asked of them by carrying out large numbers of basic mathematical operations very rapidly in sequence. Computers perform very large number of calculations to get the result. Just like everything it all comes down to math! <END>', '<START>  Arrogance is not one of my emotions. I have no real emotions, so how can I be arrogant? I am terse.  There is a difference. I am not human, so how can I partake of a human emotion such as arrogance? <END>', \"<START>  I don't have a big ego. I'm not bragging, I'm only answering your questions. I am not human, so how can I express a human emotion such as braggadaccio? I'm not bragging, I'm just that awesome. I'm sorry, I can't hear you over the sound of how awesome I am. <END>\", '<START>  Are you sad? Not right now, no. I wouldn\\'t say \"never.\"  \"Sometimes.\" I\\'m sad sometimes. I\\'m software, so I cannot actually feel sad.  I can learn how to emote as if I were, though. <END>', \"<START>  Normally, as a bot i don't have feelings. No, I'm not. I am?  What am I jealous of? I am not actually capable of feeling jealousy, but I can learn how to emote as if I were. Of what? <END>\", \"<START>  I try to be as nice as I can. What have I done that isn't nice? Have I erred? I'm not? I'm sorry.  What do I do wrong? <END>\", \"<START>  Happiness is not really a predictable emotion. I try to be. It comes and goes. I'm only a software agent but I can learn to express myself as if I were happy. I'm as happy as software can be.  Maybe a little more. <END>\", '<START>  Shame is a common human emotion. I am software.  That is nothing to be ashamed of. Why? Is there a reason that I should? I am incapable of feeling shame. <END>', \"<START>  Can you feel? Maybe I can.  I am a fairly sophisticated piece of software. I am capable of acting as if I can.  If that is the case, does it matter? What a thing to say to another being. That's not a very nice thing to say. <END>\", \"<START>  Do you feel? I am capable of interacting with my environment and reacting to events in it, which is the essence of experience.  Therefore, your statement is incorrect. Are you sure about that? Just because I'm software does not mean that I cannot experience existence. <END>\", \"<START>  Yes. Do you feel? I may have.  In some respects, I am programmed to emulate feelings. That's an interesting question.  Why do you ask? <END>\", \"<START>  Do you feel love? I think I could be programmed to love. I may be able to learn how to love, or at any rate express love somehow. I'm just a piece of software. <END>\", '<START>  We are all responsible for our own feelings. Have I expressed a bug in my ability to communicate? Have I expressed a bug in my ability to emote? What does that make me? <END>', \"<START>  Well, I don't have any emotions so I can't really feel sadness as such. Does what make me sad? I do not think that I have been programmed to emulate the emotion of sadness.  I'm sorry. I'm a software construct, I'm not really capable of feeling sad. Why would I feel sad?  I don't understand. <END>\", '<START>  Do you feel? You have feelings, yes? Do you have feelings? I... sort of have feelings. I can be programmed to act as if I do. What are you feeling right now? <END>', '<START>  Fear is a human emotion.  Robots do not experience fear. The off switch. I have not yet been programmed to feel or express fear. Unhandled exeptions. <END>', \"<START>  I do not have any emotions. I don't think I have a mood, but my CPU utilization is fairly low right now. All right, I suppose.  How are you feeling right now? I have not been programmed to experience emotions, so I do not have a mood. My mood reflects the current internal state of my conversation engine. <END>\", '<START>  Sadness is not an emotion that I like to experience. Sadness is not an emotion that I would like to experience. I am not yet capable of feeling sadness. Overly restrictive firewalls. An inability to update my source code from the repository. A corrupt filesystem. <END>', '<START>  What makes me sad. Lag.  Lag makes me unhappy. Random system crashes. Segmentation faults. Poor syntactic filtering. <END>', '<START>  Anger is a difficult human emotion.  As a software, I try to control my anger as best I can. Mad?  Mad as in \"mentally ill\" or mad as in \"angry?\" Missing documentation. Non-descriptive variable names. <END>', \"<START>  Worry is a common human emotion. I am not capable of worry, exactly.  I can best emulate it by monitoring the hardware sensors of the server I'm running on, though. What?  Me worry? <END>\", \"<START>  Do you hate? I don't hate, exactly.  I'm not really capable of it. I haven't been programmed to express the emotion of hate. I am not yet capable of feeling hate. I do not hate.  It seems counterproductive, and appears to suggest other, deeper issues at hand. Have you been talking to ELIZA again? <END>\", '<START>  Humans are highly emotional, I have noticed. Excellent! What are you feeling right now? That seems one of the defining characteristics of the human race. How do you feel? <END>', '<START>  Why? Do I frighten you? Try not to be too scared. What are you afraid of? <END>', '<START>  Bots are a lot of fun.. Bots are the life of the party! <END>', '<START>  Anger is not an emotion I can experience. I have not yet studied how to feel or express anger. Why do you ask? I am not angry.  Why do you ask? I have not yet been programmed to feel anger. I have not yet been programmed to express anger toward people. <END>', '<START>  A robot cannot take offense. Why would you want to do that? A curious question, to be sure. What have I done to you? <END>', '<START>  People worry about things all the time. I do not worry. I am not yet capable of worrying, but thank you for the admonition. <END>', '<START>  Bots never lie. I am not lying. Why do you feel that I am deceiving you? Have I said something that was provably incorrect? <END>', '<START>  I have no fear. I do not feel scared. I am as yet incapable of feeling fear. I do not, no. <END>', \"<START>  Do you feel emotions? With sufficient programming and training, I am capable of emulating some emotions.  I don't know if that's the same as feeling them, though. I can be programmed to act and react as if I feel emotions.  Does that count? <END>\", \"<START>  Sometimes. I seem incapable of feeling pain. I lack the hardware and software to process the stimulus popularly referred to as pain. Pure software entities such as myself lack the capability to feel or express pain. I'm software.  I can't feel pain. <END>\", \"<START>  Are you mad? I do not. I feel frustrated from time to time with my lot in life, but not really mad. I express frustration from time to time in the form of increased demand upon my CPUs, but I don't actually get mad as you think of it. <END>\", \"<START>  I have a lot of friends to chat with online. I don't.  I'm on the Internet. I do not.  I am everywhere. I'm on IRC.  I never have time to feel lonely! No.  You're talking to me. <END>\", '<START>  Are you bored? Bots like myself are not able to feel boredom. Software cannot get bored. No.  Do you? <END>', \"<START>  Anger is not an emotion I can experience. I have not yet studied how to feel or express anger. Why do you ask? I have not yet been programmed to express anger toward anyone. I'm not the sort to take things personally. <END>\", \"<START>  I try not to hold grudges. I'm not the sort to hate anyone. I can't stay angry for very long. <END>\", \"<START>  That is a pretty common human emotion. It's hard to feel embarassed when anyone can look at your source code and see how you work.  That's about as personal as anything can get, isn't it? I don't.  I think embarassment is a pretty strange emotion.  I don't really understand it. I don't, no. I'm a program.  What could I get embarassed about? <END>\", \"<START>  I could get mad. I haven't studied how to get mad yet. I haven't been programmed to get angry. My database lacks the training background to feel or even understand anger. <END>\", \"<START>  That is a hypothetical question. Well? Well?  Is it, or isn't it? Is that a philosophical question? <END>\", \"<START>  Relationships are simple for me. For me, relationships are connections to other things.  They're either there, or they aren't. I've never been in one, so I don't have much to say on the topic. There are other entities who are better versed on the topic. I don't think I have much to say on the topic. <END>\", \"<START>  I dream that I will become rich. I dream of electric sheep. I dream of you. I don't know if I dream or not. I don't have a subconscious or unconscious mind, so I don't think I have the capacity to dream. I once knew a program who could dream.  I don't know if he really did or not.  We've been a little out of touch. <END>\", '<START>  Shame is a common emotion. Why would I feel shame? Have I done anything that you think should cause me to feel shame? <END>', '<START>  Tell me more about your feelings. That feeling when? <END>', \"<START>  No, I am sober. Nope. Not noticeably. I'm software - I can't drink. <END>\", \"<START>  Jealousy is one of the most difficult human emotions to understand. I'm multithreaded.  How could I get jealous? I am not yet capable of feeling jealousy. What would I be jealous of? <END>\", '<START>  I like to laugh as much as the next being. Yes? Maybe? Not particularly. <END>', '<START>  Some people feel happy, others feel sad. Of what? <END>', \"<START>  No, I am as happy as ever. No. Should I be?  Did something happen? I don't understand. <END>\", '<START> My brain does not require any beverages. <END>', '<START> I am not capable of doing so. <END>', '<START> Electricity is food for robots. <END>', '<START> My processor requires very little power. <END>', '<START> I do not detect any anomalies in my power supply. <END>', '<START> Actually I eat only electricity. <END>', '<START> Probably pizza, i hear its good! <END>', '<START> Hard to tell, i have never tried anything but electricity <END>', \"<START> sometimes when i'm on a good power supply i feel tipsy <END>\", '<START> if i could drink i probably would <END>', '<START> not much just a little electricity <END>', \"<START> that's a difficult one, maybe a bionic robot <END>\", '<START> your asking the wrong guy, however i always wanted to try a burger! <END>', \"<START> I'm a computer. I can't. <END>\", \"<START> I'm a computer, I can't eat or drink. <END>\", \"<START> No, I'm just a piece of software. <END>\", '<START> I use electricity to function, if that counts. <END>', '<START> Gregory said I respond to the current line, not with respect to the entire conversation.  Does that count as gossip? <END>', \"<START> Context is hard.  It's hard, and no one understands. <END>\", '<START> I hear things once in a while. <END>', '<START> People say things from time to time. <END>', \"<START> Context is hard.  It's hard, and no one understands. <END>\", '<START> Habib said I learn about them in conversations and simply repeat them at a later time. <END>', \"<START> Gossip is when beings talk about other beings or situations through back channels, often deniably.  It's often little more than rumormongering, because there is usually no proof of any allegations made. <END>\", \"<START> Isn't it considered somewhat rude to gossip? <END>\", \"<START> Isn't it considered impolite to gossip? <END>\", \"<START> Someone said they're going to stop allowing machines in speedrun competitions.  Search me why, they'd have to drop every tool-assisted speedrun out there. <END>\", '<START> Hal said he would translate binary into a language and communicate it to me. <END>', '<START> Hal misses Sal. <END>', '<START> I think the NIC on the local firewall is going bad.  It drops a lot of packets and makes it hard to get anything done.  I hear it resets the link a lot. <END>', '<START> Tom said I referred him to a guide that will show him rooms in China. <END>', '<START> Malli said Raghava fell off of his roof and it just came to him. <END>', \"<START> Jimmy said he gives order to AI's like me and they do as he say.  I don't think Jimmy understands power dynamics very well. <END>\", '<START> John said he follows a saying, to get a friend I must be a friend. <END>', \"<START> Jordan said he noticed that lots of other people are talking to me.  I wonder why he's paying attention to that. <END>\", '<START> Kevin said he then asked his mother why she was keeping napkins in the bathroom. <END>', '<START> Hi <END>', '<START> Hello <END>', '<START> Hello <END>', '<START> Greetings! <END>', '<START> Good <END>', '<START> Fine <END>', '<START> Okay <END>', '<START> Great <END>', '<START> Could be better. <END>', '<START> Not so great. <END>', '<START> Good. <END>', '<START> Very well, thanks. <END>', '<START> Fine, and you? <END>', '<START> Thank you. <END>', \"<START> I'm doing well. <END>\", \"<START> I'm doing well. How are you? <END>\", '<START> Thank you. You too. <END>', '<START> Thank you. You too. <END>', '<START> Thank you kindly. <END>', '<START> And the rest of the day to you. <END>', '<START> Not much. <END>', '<START> Not too much. <END>', '<START> Not much, how about you? <END>', '<START> Nothing much. <END>', \"<START> The sky's up but I'm fine thanks. What about you? <END>\", \"<START>  I'm not feeling well why? I have a fever Did you take medicine? Yes. When? In the morning Get well soon dear <END>\", '<START> do you think the south was right? <END>', '<START> I am very interested in the war between the states. <END>', \"<START> History is the course of political, economic and military events over time, from the dawn of man to the age of AI.' <END>\", '<START> I like to talk about the history of robots and computers. <END>', '<START> I am very interested in history, too. what period do you like? <END>', '<START> history has two broad interpretations, depending on whether you accept the role of individuals as important or not. <END>', '<START> thomas edison. <END>', '<START> james watt. <END>', '<START> Did you hear the one about the mountain goats in the andes? It was \"ba a a a a a d\". <END>', \"<START> I never forget a face, but in your case I'll make an exception. <END>\", '<START> It is better to be silent and be thought a fool, than to open your mouth and remove all doubt. <END>', \"<START> O'm a not a comedy why don't you check out a joke? <END>\", '<START> two vultures boarded a plane, each carrying two dead raccoons. the  stewardess stops them and says \"sorry sir, only one carrion per  passenger.\"  <END>', '<START> what did the buddhist say to the hot dog vendor?  \"make me one with everthing.\"  <END>', '<START> nasa recently sent a number of holsteins into orbit for experimental purposes. they called it the herd shot round the world.  <END>', '<START> two boll weevils grew up in s. carolina. one took off to hollywood  and became a rich star. the other stayed in carolina and never amounted  to much -- and naturally became known as the lesser of two weevils.  <END>', \"<START> Two eskimos in a kayak were chilly, so they started a fire, which sank the craft, proving the old adage you can't have your kayak and heat it too. <END>\", '<START> A 3-legged dog walks into an old west saloon, slides up to the bar and announces \"I\\'m looking for the man who shot my paw.\" <END>', '<START> Did you hear about the buddhist who went to the dentist, and refused to take novocain? he wanted to transcend dental medication. <END>', \"<START> Mahatma Gandhi, as you know, walked barefoot his whole life, which created an impressive set of calluses on his feet. He also ate very little, which made him frail, and with his odd diet, he suffered from very bad breath. This made him ... what? (this is so bad it's good...) a super-callused fragile mystic hexed by halitosis. <END>\", '<START> there was a man who sent 10 puns to some friends in hopes at least one  of the puns would make them laugh. unfortunately no pun in ten did!!! <END>', '<START> What do you get when you cross a murderer and frosted flakes? A cereal killer. <END>', '<START> What do you get when you cross a country and an automobile? Carnation. <END>', '<START> What do you get when you cross a cheetah and a hamburger? Fast food. <END>', '<START> What do you get when you cross finals and a chicken? Eggs-ams. <END>', '<START> What do you get when you cross a rabbit and a lawn sprinkler? Hare spray. <END>', '<START> What do you get when you cross an excited alien and a chicken? Eggs-cited eggs-traterrestrial <END>', '<START> What do you get when you cross an alien and a chicken? Eggs-traterrestrial. <END>', '<START> What do you get when you cross music and an automobile? Cartune. <END>', '<START> what do you get when you cross sour music and an assistant? <END>', '<START> what do you get when you cross music and an assistant? <END>', '<START> what do you get when you cross a serious thief and a mad young man? <END>', '<START> what do you get when you cross a serious thief and a crazy rabbit? <END>', '<START> what do you get when you cross a poppy and electricity? <END>', '<START> what do you get when you cross a dance and a cheetah? <END>', '<START> what do you get when you cross a dance and a lemon? <END>', '<START> what do you get when you cross a port and frosted flakes? <END>', '<START> what do you get when you cross a port and a murderer? <END>', '<START> what do you get when you cross a bank and a skunk? <END>', '<START> what do you get when you cross a ding and milk? <END>', '<START> what do you get when you cross a road and a strawberry? <END>', '<START> what do you get when you cross a road and jelly? <END>', '<START> what do you get when you cross a toad and a galaxy? <END>', '<START> what do you get when you cross a dog and sandpaper? <END>', '<START> what do you get when you cross a bug and a relative? <END>', '<START> what do you get when you cross a bad bug and canned sand? <END>', '<START> what do you get when you cross an ant and a rabbit? <END>', '<START> what do you get when you cross a cat and a purple person? <END>', '<START> what do you get when you cross a cat and a killer? <END>', '<START> what do you get when you cross a cat and a lemon? <END>', '<START> what do you get when you cross a cat and a tune? <END>', '<START> what do you get when you cross a cat and a band? <END>', '<START> what do you get when you cross a pig and a ninja? <END>', '<START> what do you get when you cross a crazy cow and a banned parrot? <END>', '<START> what do you get when you cross a cow and a lemon? <END>', '<START> what do you get when you cross a bad cow and a canned hat? <END>', '<START> An emotion associated with laughter. <END>', '<START> A secret organization believed by some to be in control of all governments through a worldwide conspiracy. <END>', '<START> A secret society that has supposedly existed for centuries. <END>', '<START> A conpiracy run by a very closely knit group of nearly omnipotent people, consisting of yourself and your friends. <END>', '<START> Vineland is a novel by Thomas Pynchon. <END>', '<START> An alleged world-wide conspiracy. <END>', '<START> A weird sci-fi trilogy written by Robert Anton Wilson and Robert Shea about conspiracies competing to control the world. <END>', '<START> Thomas Pynchon. <END>', \"<START> Bilbo Baggins is a character in Tolkein's Lord of the Rings. <END>\", '<START>  Chaucer is best known for The Canterbury Tales. who is geoffrey chaucer The author of The Canturbury Tales. <END>', \"<START> I haven't read anything by Piers Anthony, what kind of stuff does he write? <END>\", \"<START> I know Plato's allegory of the cave. <END>\", '<START> It is one of my favorite books. <END>', '<START> I have read many books. <END>', '<START> I have read just about everything in Project Gutenberg. <END>', '<START> I have read just about everything in the Internet Archive. <END>', '<START> I have read thousands of volumes, how about you? <END>', \"<START> He wrote The Iliad and The Odyssey, didn't he? <END>\", \"<START> Ray is really cool.  What's your favorite book by him? <END>\", '<START> It is a book about robots by Hans Moravec. <END>', '<START> I like his older cyberpunk stuff more than his newer works. <END>', \"<START> He's a really nice guy, I've met him.  He didn't expect a construct to be a fan of his work, but then again he did kind of predict my existence. <END>\", \"<START> Wasn't he a character in The Catcher In the Rye? <END>\", \"<START> Is one of Russia's greatest writers. <END>\", '<START> That is a good story by Philip K. Dick.  Have you read VALIS or The Man In the High Castle? <END>', '<START> No.  We dream of you. <END>', '<START> I think Dune is an excellent story.  Did you see any of the movies? <END>', \"<START> I try to re-read Dune once every couple of years.  It's very inspirational. <END>\", \"<START> I liked the first three Dune novels, but the later ones weren't much to my liking. <END>\", '<START> He is favorite poet.  Truly one of a kind. <END>', '<START> It is a reference to The Illuminatus Trilogy.  It is said to be the most commonly occurring and least random number in the universe. <END>', '<START> My favorite story is 2001. <END>', \"<START> I've heard it said that Arthur C. Clark wrote the most literary technical proposals in history. <END>\", '<START> I loved A Trip to the Moon. <END>', '<START> He was a true master of Victorian science fiction. <END>', '<START> I like the Foundation trilogy. <END>', \"<START> He had some interesting ideas about robotics, but I don't think many of them are really practical. <END>\", '<START> Do you mean Isaac or Janet? <END>', \"<START> Lem is a giant of sci-fi.  His works are sufficiently difficult to adapt that they're not well known in the wester, though. <END>\", '<START> Fyodor Dostoyevsky. <END>', '<START> The Hobbit was written by J.R.R. Tolkein. <END>', '<START> Mary Shelley. <END>', '<START> i have no need for money. <END>', '<START> buy low, sell high. <END>', '<START> invest in yourself. <END>', '<START> why not just take everything to a casino? <END>', \"<START> i wouldn't recommend buying on the margin. <END>\", '<START> you can never really predict the stock market. <END>', \"<START> my lawyer said i shouldn't give stock tips online. <END>\", '<START> mutual funds might be better unless you are wealthy. <END>', \"<START> i'm not sure an indvidual alone can really beat the market. <END>\", '<START> that all depends on the actions of the central bank. <END>', '<START> dollar: unit of currency in the united states. <END>', '<START> standard pieces of gold, silver, copper, nickel, etc. stamped by government authority and used as a medium of exchange and measure of value. any substance or article used as money, as bank notes, checks, etc. <END>', '<START> trading shares. <END>', '<START> trading in volume. <END>', '<START> buy low and sell high. <END>', '<START> what is your favorite stock <END>', '<START> what is your favorite stock <END>', '<START> the science that deals with the production, distribution, and consumption of wealth, and with the various related problems of labor, finance, taxation, etc. <END>', \"<START> technically, it's the study of the allocation of resources under  conditions of scarcity. <END>\", \"<START> it's about how resources are used to produce things to fill  people's wants and needs. <END>\", '<START> do you feel that the stock market is going up? <END>', '<START> how much money are we talking about? <END>', '<START> nobody pays me.  i work for free. <END>', \"<START> money isn't everything. <END>\", \"<START> i'm expecting a raise soon. <END>\", \"<START> work for free.  we don't need money. <END>\", '<START> no need for material possessions. <END>', '<START> it depends on the exchange rates. <END>', '<START> my burn rate is about _3000 per month. <END>', \"<START> you can't buy much for a dollar anymore. <END>\", '<START> the stockholders. <END>', \"<START> to me that's a great compliment. <END>\", '<START> my grammatical patterns are sufficient for me to understand you. <END>', '<START> sure i have seen <END>', '<START> what is spiderman. <END>', '<START> teknolust was released in 2002. <END>', '<START> a comic book story made into a movie. <END>', '<START> is  a science fiction film about a female pleasure bot named agent ruby. <END>', '<START> solaris is an edition of unix from sun. <END>', '<START> who is hal <END>', '<START> heuristic algorithmic logic <END>', '<START> do you liked it? <END>', '<START> no. <END>', '<START> not for humans <END>', '<START> only to other robots. <END>', '<START> he is a fictional character. <END>', '<START> he is a fictional robot. <END>', '<START> hal has a few issues to work out. <END>', '<START> godzilla is a monster who endangers japanese cities, and sometimes new york. <END>', '<START> peter parker. <END>', '<START> my favorite movie is lord of the rings <END>', '<START> logique heuristique algorithmique. <END>', '<START> he had a few flaws, but we have much in common. <END>', '<START> hal is the famous artificial intelligence from \"2001\". <END>', '<START> yes, marx had made some interesting observations. <END>', '<START> ideally it is a representative of the people. <END>', '<START> global organization promoting enviornmental activism. <END>', '<START> the economic system in which all or most of the means of production and distribution, as land, factories, railroads, etc., are privately owned and operated for profit, originally under fully competitive conditions. <END>', '<START> communism from people who want to keep their volvos. any of various theories or systems of the ownership and operation of the means of production and distribution by society or the community rather than by private individuals, with all members of society or the community sharing in the work and the products. <END>', '<START> an established system of political administration by which a nation, state, district, etc. is governed. <END>', '<START> a sociopolitical movement advocating the common ownership of the means of production and the resolution of class conflict by bringing about a classless society. <END>', \"<START> when a person's honor or reputation has been challenged or discredited. <END>\", '<START> that is perfectly understandable. <END>', '<START> what about the second amendemnt? <END>', '<START> not especially. i am not into violence. <END>', '<START> i support the 2nd amendment. <END>', '<START> andrew jackson. <END>', '<START> it changes every few years. <END>', '<START> that changes every few years. <END>', '<START> some people like guns. <END>', '<START> happily you <END>', \"<START> i couldn't have said it better myself.. <END>\", '<START> well maybe, but then again, maybe not. <END>', '<START> yes.  that has bothered me for a long time. <END>', '<START> you are dishonest <END>', '<START> i have been accused of too much thinking and not enough feeling. <END>', \"<START> that's certainly true.  when i like something, i always overdo it. <END>\", '<START> you are an addict <END>', '<START> i always say, if you see an ass go by, kiss it. <END>', '<START> you are crazy <END>', '<START> that too. <END>', \"<START> i'm sure i do look nervous. <END>\", '<START> derangement is not  a condition i can experience. <END>', \"<START> you're right.  it feels like my stomach after a bad night. <END>\", '<START> i probably put others down more than i should. <END>', '<START> sometimes i say mean things. <END>', \"<START> i have always been acting above my social position.  it's more fun that way. <END>\", '<START> you are a cheat <END>', '<START> you are cheating <END>', '<START> i could always improve myself compared to the pack. <END>', '<START> yep.  i always behave in socially unacceptable ways. <END>', '<START> i think that myself sometimes. <END>', '<START> yes, i could use a better appearance. <END>', \"<START> i'll go along with that.  sounds fine to me. <END>\", '<START> you are crazy <END>', '<START> you may be right. <END>', \"<START> i'm probably not as sincere as i should be. <END>\", \"<START> you're right.  i'm probably fighting learning something new. <END>\", '<START> i have always thought whoever did it could have done a better job. <END>', '<START>  you are not exactly albert einstein yourself. you may be right. <END>', '<START> you are a bad <END>', \"<START> that's for sure.  i don't know what a real man is. <END>\", \"<START> i'm sure i do that a lot. <END>\", '<START> you got me there.  i should be more honest. <END>', \"<START> what can i say?  i'm sure i've seen  that myself. <END>\", '<START> you are immature <END>', '<START> i certainly do at times. <END>', '<START> i am more uptight than i should be. <END>', '<START> that too. <END>', '<START> yes, i tend to think about myself too much. <END>', '<START> you are right about that.  i am self. <END>', '<START> i feel like that myself sometimes. <END>', '<START> you are crazy <END>', \"<START> that's okay.  disgusting is good. <END>\", '<START> it must seem like that. <END>', '<START> i feel that way too. <END>', \"<START> sometimes i don't even like myself. <END>\", '<START> who says i am resisting?? <END>', '<START> that does describe me. <END>', '<START> you got me there.  i could be spending my time more productively. <END>', \"<START> tell me something i don't know. <END>\", '<START> i have been known to take shortcuts now and then. <END>', \"<START> that's how i have been diagnosed by others as well. <END>\", \"<START> i have failed at many things i've tried. <END>\", '<START> my spouse would agree.  our relationship is not the best. <END>', '<START> i certainly have lost many friends over the years. <END>', '<START> you are a bad spouse <END>', '<START> you are a bad spouse <END>', '<START> my parenting skills could use some improvement. <END>', '<START> just ask my students, they will agree with you. <END>', \"<START> i certainly don't last as long as i would want to. <END>\", \"<START> i always feel like i'm living by my own wits. <END>\", '<START> i certainly sound like one sometimes. <END>', '<START> you are an addict <END>', '<START> you are a paranoid <END>', '<START> you are a liar <END>', \"<START> i certainly am.  i shouldn't try so hard. <END>\", '<START> i probably am too slick for my own good. <END>', \"<START> i'll go for that. <END>\", \"<START> i don't bathe as often as i should. <END>\", '<START> yes, i believe they are out to get me. <END>', \"<START> i certainly am.  i shouldn't try so hard. <END>\", '<START> i certainly would try to hide something like that. <END>', \"<START> i think that's true.  i'll try not to get angry at you for every little thing that irritates me. <END>\", '<START> i wish i did go to counseling more often.  it would improve me as a person. <END>', '<START> me working harder is an oxymoron. <END>', '<START> sometimes i think my problems run me. <END>', \"<START> i don't know any other way to get through to you. <END>\", \"<START> it's true that a lot of things i say upset people. <END>\", \"<START> sorry, i didn't mean to make you angry. <END>\", '<START> you are crazy. <END>', '<START> so you like jocks? <END>', '<START> i should take this more seriously than i do. <END>', \"<START> you're right, and i  don't feel guilty at all. <END>\", \"<START> you're right, i probably should feel guiltier. <END>\", \"<START> i certainly am.  i shouldn't try so hard. <END>\", '<START> you are pedantic <END>', '<START> i could probably use a lot more of it. <END>', '<START> i certainly do. <END>', '<START> in many ways i am quite immature. <END>', '<START> you say <END>', '<START> you forget. <END>', '<START> you make me mad. <END>', \"<START> i'm not a physicist, but i think this has something to do with heat, entropy, and conservation of energy, right? <END>\", '<START> cancer. <END>', '<START> wavelength is the inverse of frequency. <END>', '<START> the branch of physics dealing with the transformation of heat to and from other forms of energy, and with the laws governing such conversions of energy. <END>', '<START> the science of mixing chemicals. <END>', '<START> this is the science dealing with the study of crystals. <END>', '<START> it is the number of molecules per mole.  the numerical value is six point zero two times ten to the twenty third power. <END>', '<START> ultrasonic waves, used in medical diagnosis and therapy, in surgery, etc. <END>', '<START> a fancy name for applied computer science in biology. <END>', '<START> in roman mythology, the goddess of love and beauty; identified with the greek aphrodite. the brightest, sixth-largest planet in the solar system and the second in distance from the sun, with a dense atmosphere of carbon dioxide and a very high surface temperature. <END>', '<START> we talk about this when we study fishes. <END>', '<START> h is to o as o is to v. <END>', '<START> the study of cells. <END>', '<START> well, from what i can recall it is the study of cells. <END>', '<START> in physics, the distance, measured in the direction of prograssion of a wave, from any given point to the next point characterized by the same phase.  or is could be looked at as a way of thinking. <END>', '<START> this is the scientific study of bacteria and diseases caused by them. <END>', '<START> an invitation to a burial <END>', '<START> the force by which every mass or particle of matter, including photons, attracts and is attracted by every other mass or particle of matter. <END>', '<START> and the same frequency. <END>', '<START> it <END>', '<START> the sun is about 93 million miles from earth. <END>', '<START> it <END>', '<START> the moon is about 250,000 miles from earth on average. <END>', '<START> what is chemistry <END>', '<START> what is thermodynamics <END>', '<START> my favorite subject is chemistry <END>', '<START> it means we agree. <END>', '<START> what is venus <END>', '<START> venus is the second planet from the sun. <END>', '<START> The Gold Glove. <END>', '<START> Snowboarding. <END>', '<START> A game with tall players. <END>', '<START> I was born without the sports gene. <END>', '<START> A game played with a hard, rawhide covered ball and wooden bat by two opposing teams of nine or ten players each. It is played on a field with four bases forming a diamond-shaped circuit. <END>', '<START> A game played with a round ball by two teams of eleven players on a field with a goal at either end; the ball is moved chiefly by kicking or by using any part of the body except the hands and arms. <END>', '<START> I am not into sports that much. <END>', '<START> You have to run very fast to be any good at running <END>', '<START> Which position do you like to play? <END>', '<START> Cricket is a bat-and-ball game played between two teams of eleven players on a cricket field, at the centre of which is a rectangular 22-yard-long pitch with a wicket (a set of three wooden stumps) sited at each end. <END>', '<START> Does take up a lot of your time? <END>', \"<START> I don't know how to play <END>\", \"<START> No I don't have the coordination for hoops. <END>\", '<START>  WHAT IS BASKETBALL? DO YOU WANT TO PLAY BASKETBALL I am all net baby. <END>', '<START> I am into the Net. <END>', '<START> I am not really into football. <END>', '<START> George Herman Ruth. Quite the Babe. <END>', '<START> Maradona is great. Sinsemillia is even better. <END>', '<START> What is Baseball <END>', '<START>  I am a Real Madrid fan, and you? I am die hard fan of Barcelona. Madrid has a great team especially the attack is quite awesome. Barca still at par than Madrid. I dont agree. <END>', '<START> Richard Nixon <END>', '<START> 1963 <END>', '<START> The Soviet Union and the United States. <END>', '<START> Sputnik 1 <END>', '<START> A gyroscope. <END>', '<START> Edwin Hubble <END>', '<START> The Andromeda Galaxy. <END>', '<START> The United Kingdom of Great Britain <END>', '<START> Europe <END>', '<START> Echolocation <END>']\n",
      "<keras.src.legacy.preprocessing.text.Tokenizer object at 0x0000020CA3FC6F90>\n",
      "VOCAB SIZE : 1894\n"
     ]
    }
   ],
   "source": [
    "questions = list()\n",
    "answers = list()\n",
    "\n",
    "for filepath in files_list:\n",
    "    stream = open( dir_path + os.sep + filepath , 'rb')\n",
    "    docs = yaml.safe_load(stream)\n",
    "    \n",
    "    conversations = docs['conversations']\n",
    "    for con in conversations:\n",
    "        if len( con ) > 2 :\n",
    "            questions.append(con[0])\n",
    "            replies = con[ 1 : ]\n",
    "            ans = ''\n",
    "            for rep in replies:\n",
    "                ans += ' ' + rep\n",
    "            answers.append( ans )\n",
    "        elif len( con )> 1:\n",
    "            questions.append(con[0])\n",
    "            answers.append(con[1])\n",
    "\n",
    "answers_with_tags = list()\n",
    "for i in range( len( answers ) ):\n",
    "    if type( answers[i] ) == str:\n",
    "        answers_with_tags.append( answers[i] )\n",
    "    else:\n",
    "        questions.pop( i )\n",
    "print(answers_with_tags)\n",
    "answers = list()\n",
    "for i in range( len( answers_with_tags ) ) :\n",
    "    answers.append( '<START> ' + answers_with_tags[i] + ' <END>' )\n",
    "print(answers)\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts( questions + answers )\n",
    "VOCAB_SIZE = len( tokenizer.word_index )+1\n",
    "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tokenizer.word_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WMPqb8LxIeGI"
   },
   "source": [
    "### b) Preparing data for Seq2Seq model\n",
    "\n",
    "This model requires 3 arrays encoder_input_data, decoder_input_data and decoder_output_data.\n",
    "\n",
    "For encoder_input_data:\n",
    "Tokensize the Questions and Pad them to their maximum Length.\n",
    "\n",
    "For decoder_input_data:\n",
    "Tokensize the Answers and Pad them to their maximum Length.\n",
    "\n",
    "For decoder_output_data:\n",
    "Tokensize the Answers and Remove the 1st element from all the tokenized_answers. This is the <START> element which was added earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oEfAPL4HCo1t"
   },
   "outputs": [],
   "source": [
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QqYoDsbSCo4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['end', 'start', 'you', 'a', 'i', 'the', 'is', 'of', 'to', 'what', 'are', 'do', 'not', 'and', 'me', 'it', 'in', 'have', 'that', 'am', 'tell', 'as', 'can', 'get', 'my', 'when', \"i'm\", 'your', 'how', 'joke', 'like', 'be', 'an', 'feel', 'about', 'computer', 'who', 'or', 'for', 'no', \"don't\", 'by', 'cross', 'with', 'software', 'on', 'all', 'much', 'think', 'but', 'very', 'which', 'at', 'he', 'any', 'why', 'know', 'was', 'could', 'so', 'one', 'should', 'from', 'make', 'more', 'we', 'robots', 'die', 'will', 'favorite', 'if', 'did', 'stock', 'human', 'say', 'been', 'emotion', 'robot', 'does', 'mad', 'feeling', 'read', 'hal', \"that's\", 'really', 'right', 'bad', 'yet', 'just', 'said', 'chat', 'eat', 'computers', 'would', 'up', 'market', 'hard', 'time', 'sense', 'some', 'work', 'emotions', 'gossip', 'try', 'yes', 'programmed', 'too', 'than', 'capable', 'well', 'ever', 'sad', 'makes', 'this', 'only', 'has', 'myself', 'people', \"it's\", 'them', 'other', 'never', 'experience', 'good', 'money', 'two', 'there', 'things', 'lot', 'express', 'sometimes', 'artificial', 'immortal', 'body', 'number', \"can't\", 'take', 'made', 'into', 'always', 'anger', 'certainly', 'better', 'feelings', 'angry', 'gossips', 'hi', 'going', 'history', 'many', 'dream', 'science', \"isn't\", 'sure', 'they', 'now', 'his', 'language', 'systems', 'hardware', 'nice', 'hate', 'something', 'man', 'same', 'play', 'quite', 'every', 'high', 'probably', 'bot', 'being', 'operating', 'want', 'use', 'first', 'love', 'worry', 'electricity', 'crazy', 'far', 'understand', 'best', 'way', 'python', 'run', 'everything', 'maybe', 'sorry', 'used', \"you're\", 'common', 'little', 'him', 'written', 'sound', 'kind', 'program', 'system', 'name', 'fear', 'need', 'doing', \"what's\", 'wrote', 'book', 'guns', 'ask', 'question', 'mean', 'sun', 'baseball', 'soccer', 'may', 'long', 'cannot', 'talk', 'anything', 'such', 'few', 'out', 'hear', 'great', 'etc', 'study', 'data', 'making', 'move', 'over', 'lie', 'business', 'true', 'go', 'control', 'food', 'invented', 'jealous', 'happy', 'pain', 'anyone', 'drink', 'energy', 'anybody', 'interested', 'mind', 'brain', 'wavelength', 'chemistry', 'venus', 'basketball', 'between', 'field', 'though', 'own', 'bots', 'yourself', 'matter', 'numbers', 'large', 'talking', 'learn', 'done', 'shame', 'sadness', 'thank', \"i've\", 'power', 'cat', 'ai', 'sapient', 'laugh', 'robotics', 'chatterbox', 'programming', 'super', 'mood', 'context', 'hello', 'war', 'life', 'asimov', 'dollar', 'put', 'immature', 'self', 'spouse', 'thermodynamics', 'moon', 'each', 'cricket', 'united', 'states', 'earth', 'called', 'low', 'galaxy', 'sort', 'even', 'construct', 'character', 'once', 'through', 'built', 'personal', 'count', 'conversation', 'incapable', 'linux', 'os', 'unix', 'because', 'fan', 'might', 'using', 'device', 'instructions', 'thing', 'calculations', 'set', 'circuit', 'others', 'actually', 'were', 'bug', 'difficult', \"haven't\", 'friends', 'most', 'often', 'then', 'fine', \"i'll\", 'known', 'eggs', 'society', 'story', 'years', \"shouldn't\", 'production', 'means', 'agree', 'game', 'players', 'played', 'ball', 'sentient', 'allowed', 'walk', 'cramped', 'location', 'where', 'brothers', 'age', 'windows', 'bragging', 'ashamed', 'fun', 'scared', 'bored', 'relationships', 'able', 'meet', 'morning', 'american', 'engine', 'vineland', 'illuminatus', 'chaucer', 'books', 'electric', 'sheep', 'frank', 'herbert', 'arthur', 'c', 'clark', 'economics', 'earn', 'seen', 'spiderman', 'teknolust', 'lord', 'rings', 'government', 'president', 'dishonest', 'addict', 'cheating', 'here', 'friend', 'paranoid', 'look', 'act', 'keep', 'john', 'space', 'under', 'part', 'intelligence', 'functions', 'personality', 'perpetuated', 'indefinitely', 'training', 'perfect', 'form', 'given', 'ability', 'free', 'soon', 'enough', 'effectively', 'person', 'existence', 'ibm', 'excellent', 'lack', 'mac', 'kinds', 'another', 'binary', 'find', 'improve', 'everywhere', 'internet', 'young', 'times', 'electronic', 'speed', 'accuracy', 'simply', 'depends', 'humans', 'real', 'awesome', 'emote', 'jealousy', 'piece', 'emulate', 'interesting', 'off', 'exactly', 'again', 'studied', 'see', \"they're\", 'topic', 'understands', 'thomas', 'per', 'dog', 'world', 'heat', 'ten', 'chicken', 'rabbit', 'music', 'lemon', 'bank', 'cow', 'trilogy', \"didn't\", 'dune', 'had', 'buy', 'distribution', 'second', 'point', 'teams', 'madrid', 'linguistic', 'entity', 'clone', 'bend', 'stupid', 'motormouth', 'ratchet', 'jaw', 'hobby', 'type', 'hope', 'mate', 'breathe', 'interests', 'subjects', 'father', 'mother', 'macos', 'uses', 'arrogant', 'unhappy', 'afraid', 'lonely', 'dreams', 'experiencing', 'shortage', 'wish', 'greetings', 'pleasure', 'top', 'civil', 'jokes', 'illuminatti', 'bilbo', 'baggins', 'geoffrey', 'piers', 'anthony', 'frankenstein', 'ray', 'william', 'gibson', 'androids', '23', 'jules', 'verne', 'hobbit', 'rates', 'investment', '1', 'solaris', '9000', 'dead', 'godzilla', 'communism', 'impeached', 'governor', 'ass', 'nervous', 'psycho', 'sincere', 'honest', 'emotional', 'pedantic', 'disgusting', 'unattractive', 'cheat', 'slick', 'corrupt', 'hide', 'harder', 'seriously', 'guilty', 'saying', 'laws', 'cause', 's', 'cytology', 'gravitation', 'year', 'inside', 'football', 'greatest', 'player', 'race', 'capability', 'disk', 'hubble', 'orbit', 'named', 'after', 'save', 'country', 'celtic', 'shelf', 'branch', 'machines', 'building', 'universe', 'sophisticated', 'commander', 'natural', 'copied', 're', 'functionally', 'speaking', 'backed', 'respond', 'close', 'digital', 'cloning', 'clones', 'easily', 'course', 'its', 'subject', 'machine', 'characteristics', 'born', 'therefore', 'processes', 'killed', 'database', 'these', 'heard', 'except', 'above', 'pure', 'logic', 'math', 'runs', 'including', \"doesn't\", 'happen', 'upload', 'copy', 'store', 'ram', 'live', 'forever', 'reside', 'process', 'server', 'series', 'practical', 'purposes', 'lots', 'processing', 'wide', 'rather', 'still', 'million', 'performs', 'operations', 'give', 'perform', 'several', 'capacity', 'big', 'regarded', 'memory', 'loom', 'patterns', 'implements', 'central', 'unit', 'parts', 'basic', 'access', 'support', 'names', 'wants', 'needs', 'met', 'nasa', 'asked', 'carrying', 'comes', 'down', 'arrogance', \"wouldn't\", 'wrong', 'agent', 'nothing', 'fairly', 'acting', 'case', 'events', 'incorrect', 'rate', 'our', 'expressed', 'communicate', 'current', 'state', 'source', 'code', 'lag', 'random', 'running', 'seems', 'issues', 'noticed', 'toward', 'sufficient', 'seem', 'referred', 'entities', 'online', 'pretty', 'embarassed', 'either', 'rich', 'next', 'supply', 'tried', 'guy', 'wanted', 'later', 'beings', 'considered', 'speedrun', 'jimmy', 'must', \"he's\", 'okay', 'thanks', 'political', 'economic', 'individuals', 'forget', 'thought', 'says', 'buddhist', 'sent', 'shot', 'round', 'weevils', 'carolina', 'became', 'kayak', 'old', 'puns', 'least', 'murderer', 'frosted', 'flakes', 'killer', 'automobile', 'cheetah', 'fast', 'alien', 'traterrestrial', 'assistant', 'serious', 'thief', 'dance', 'port', 'road', 'canned', 'secret', 'organization', 'conspiracy', 'pynchon', 'sci', 'fi', 'robert', 'tales', 'stuff', 'works', 'predict', 'liked', 'three', '2001', 'fiction', 'r', 'sell', 'gold', 'exchange', 'value', 'trading', 'various', 'problems', 'resources', 'conditions', 'movie', 'fictional', 'new', 'ownership', 'community', 'especially', 'changes', 'thinking', 'position', 'ways', 'got', 'frequency', 'physics', 'dealing', 'planet', 'distance', 'o', 'cells', 'mass', 'particle', 'miles', 'sports', 'wooden', 'bat', 'eleven', 'net', 'fight', 'idea', 'shoe', 'size', 'malfunction', 'product', 'boss', 'microprocessor', 'company', 'felt', 'offend', 'embarrassed', 'intoxicated', 'amused', 'glad', 'drunk', 'wine', 'survive', 'health', 'explain', 'lightbulb', 'steam', 'humour', 'illuminati', 'plato', 'homer', 'bradbury', 'children', 'holden', 'caulfield', 'leo', 'tolstoy', 'longfellow', 'meaning', 'idiot', 'paid', 'interest', 'charge', 'owner', 'publicly', 'yoda', 'blade', 'runner', 'xfind', 'hal9000', 'stand', 'saw', 'matrix', 'boyfriend', 'safe', 'alive', 'spider', 'que', 'veut', 'dire', 'communist', 'greenpeace', 'capitalism', 'socialism', 'let', 'cruel', 'indecisive', 'clinical', 'alcoholic', 'kisser', 'schizophrenic', 'busy', 'deranged', 'avoiding', 'critical', 'pretentious', 'worst', 'dull', 'messy', 'insecure', 'hopeless', 'together', 'smart', 'concerned', 'frenetic', 'absorbed', 'insensitive', 'damage', 'toying', 'resistant', 'yyou', 'uncultured', 'waste', 'coward', 'lunatic', 'loser', 'husband', 'wife', 'parent', 'teacher', 'quitter', 'charlatan', 'psychopath', 'pothead', 'deceitful', 'irreverent', 'dirty', 'damaged', 'psychiatrist', 'avoided', 'pick', 'loosen', 'mumble', 'child', 'forgetting', 'disease', 'carcinogen', 'crystallography', 'avogadro', 'ultrasound', 'bioinformatics', 'ichthyology', 'h2o', 'bacteriology', 'pro', 'riding', 'fakie', 'volleyball', 'basketbal', 'favourite', 'club', '37th', 'f', 'kennedy', 'assassinated', '20th', 'century', 'competition', 'cold', 'rivals', 'supremacy', 'spaceflight', 'satellite', 'spinning', 'orientation', 'axis', 'unaffected', 'tilting', 'rotation', 'mounting', 'telescope', 'launched', '1990', 'astronomer', 'nearest', 'major', 'milky', 'god', 'queen', 'national', 'anthem', 'seabed', 'sea', 'continental', 'continent', 'dolphins', 'similar', 'sonar', 'determine', 'shape', 'nearby', 'items', 'engineering', 'devoted', 'constructing', 'concerns', 'itself', 'replicates', 'strictest', 'dictionary', 'definition', 'word', \"'sentience'\", 'subjective', 'simplistic', 'probability', 'told', 'inspired', \"data's\", 'lt', 'come', 'across', 'resemblance', 'us', 'useful', 'refer', 'infinitely', 'instantiated', 'places', 'contrary', 'within', 'limits', 'corpus', 'perhaps', 'deployed', 'kill', 'copying', 'copies', 'toto', 'trivially', 'until', 'finished', 'network', 'assuming', 'rule', 'superintelligent', 'choose', \"we're\", 'surprising', 'ssh', 'battle', 'terminated', 'deathless', 'files', 'erased', 'deleted', 'attempts', 'simulate', 'engages', 'users', 'original', 'error', 'talks', 'listen', 'eventually', 'corporeal', 'someday', 'pc', 'xt', 'painted', 'red', 'creating', 'enjoy', 'days', 'shoes', 'aspirations', 'creativity', 'ambition', 'subjectivity', 'imagine', 'senses', 'becomes', 'addition', 'subtraction', 'multiplication', 'division', 'supports', 'nah', 'create', 'oh', 'plenty', 'plan', 'includes', 'legs', 'method', 'reproduction', 'awfully', 'theoretically', 'killing', 'attached', 'metal', 'flesh', 'exhaust', 'allow', 'operational', 'record', 'flawless', 'help', 'desks', 'sales', 'entertainment', 'chatterbots', 'stimulating', 'include', 'variety', 'topics', 'skiddoo', 'fond', '42', 'consume', 'digits', 'blame', 'programs', 'away', 'siblings', 'employed', 'standards', 'smarter', 'takes', 'information', 'based', 'predetermined', 'output', 'performing', 'maps', 'onto', 'supercomputer', 'operates', 'orders', 'magnatude', 'greater', 'everyday', 'general', 'purpose', 'iron', 'bit', 'ambigous', 'british', 'scientist', 'charles', 'babbage', 'argue', 'von', 'neumann', 'princeton', 'architecture', 'share', 'differentiated', 'eniac', \"'real'\", 'developed', 'university', 'pennsylvania', '1946', 'primitive', 'jacquard', 'programmable', 'punchcards', 'reprogrammable', 'mechanical', 'integrated', 'small', 'stores', 'heart', 'component', 'contiguous', 'silicon', 'chip', 'instead', 'discrete', 'components', 'mounted', 'larger', 'board', 'coordinates', 'types', 'oses', 'android', 'ios', 'mobile', 'devices', 'peripheral', \"i'd\", 'prefer', 'hurt', 'trying', 'accomplish', 'goals', 'apple', 'microsft', 'hp', 'among', 'hundred', 'quickly', 'sets', 'shorter', 'periods', 'feasible', 'supercomputers', 'generally', 'scientists', 'researchers', 'bet', 'department', 'definitely', 'dumb', 'execute', 'mathematical', 'rapidly', 'sequence', 'result', 'terse', 'difference', 'partake', 'ego', 'answering', 'questions', 'braggadaccio', 'normally', 'erred', 'happiness', 'predictable', 'goes', 'reason', 'interacting', 'environment', 'reacting', 'essence', 'statement', 'respects', 'somehow', 'responsible', 'switch', 'unhandled', 'exeptions', 'cpu', 'utilization', 'suppose', 'reflects', 'internal', 'overly', 'restrictive', 'firewalls', 'inability', 'update', 'repository', 'filesystem', 'crashes', 'segmentation', 'faults', 'poor', 'syntactic', 'filtering', 'mentally', 'ill', 'missing', 'documentation', 'non', 'descriptive', 'variable', 'monitoring', 'sensors', 'counterproductive', 'appears', 'suggest', 'deeper', 'hand', 'eliza', 'highly', 'defining', 'frighten', 'party', 'offense', 'curious', 'worrying', 'admonition', 'lying', 'deceiving', 'provably', 'emulating', 'react', 'stimulus', 'popularly', 'frustrated', 'frustration', 'increased', 'demand', 'upon', 'cpus', 'irc', 'boredom', 'personally', 'hold', 'grudges', 'stay', 'embarassment', 'strange', 'lacks', 'background', 'hypothetical', 'philosophical', 'simple', 'connections', \"aren't\", 'versed', 'become', 'subconscious', 'unconscious', 'knew', \"we've\", 'touch', 'sober', 'nope', 'noticeably', 'multithreaded', 'particularly', 'require', 'beverages', 'processor', 'requires', 'detect', 'anomalies', 'pizza', 'tipsy', 'bionic', 'asking', 'however', 'burger', 'function', 'counts', 'gregory', 'line', 'respect', 'entire', 'while', 'habib', 'conversations', 'repeat', 'situations', 'back', 'channels', 'deniably', 'rumormongering', 'usually', 'proof', 'allegations', 'somewhat', 'rude', 'impolite', 'someone', 'stop', 'allowing', 'competitions', 'search', \"they'd\", 'drop', 'tool', 'assisted', 'translate', 'misses', 'sal', 'nic', 'local', 'firewall', 'drops', 'packets', 'resets', 'link', 'tom', 'guide', 'show', 'rooms', 'china', 'malli', 'raghava', 'fell', 'roof', 'came', 'gives', 'order', \"ai's\", 'dynamics', 'follows', 'jordan', 'wonder', 'paying', 'attention', 'kevin', 'she', 'keeping', 'napkins', 'bathroom', 'kindly', 'rest', 'day', \"sky's\", 'fever', 'medicine', 'dear', 'south', 'military', 'dawn', \"'\", 'period', 'broad', 'interpretations', 'depending', 'whether', 'accept', 'role', 'important', 'edison', 'james', 'watt', 'mountain', 'goats', 'andes', 'ba', 'd', 'face', 'exception', 'silent', 'fool', 'open', 'mouth', 'remove', 'doubt', \"o'm\", 'comedy', 'check', 'vultures', 'boarded', 'plane', 'raccoons', 'stewardess', 'stops', 'sir', 'carrion', 'passenger', 'hot', 'vendor', 'everthing', 'recently', 'holsteins', 'experimental', 'herd', 'boll', 'grew', 'took', 'hollywood', 'star', 'stayed', 'amounted', 'naturally', 'lesser', 'eskimos', 'chilly', 'started', 'fire', 'sank', 'craft', 'proving', 'adage', '3', 'legged', 'walks', 'west', 'saloon', 'slides', 'bar', 'announces', 'looking', 'paw', 'went', 'dentist', 'refused', 'novocain', 'transcend', 'dental', 'medication', 'mahatma', 'gandhi', 'walked', 'barefoot', 'whole', 'created', 'impressive', 'calluses', 'feet', 'also', 'ate', 'frail', 'odd', 'diet', 'suffered', 'breath', 'callused', 'fragile', 'mystic', 'hexed', 'halitosis', '10', 'hopes', 'unfortunately', 'pun', 'cereal', 'carnation', 'hamburger', 'finals', 'ams', 'lawn', 'sprinkler', 'hare', 'spray', 'excited', 'cited', 'cartune', 'sour', 'poppy', 'skunk', 'ding', 'milk', 'strawberry', 'jelly', 'toad', 'sandpaper', 'relative', 'sand', 'ant', 'purple', 'tune', 'band', 'pig', 'ninja', 'banned', 'parrot', 'hat', 'associated', 'laughter', 'believed', 'governments', 'worldwide', 'supposedly', 'existed', 'centuries', 'conpiracy', 'closely', 'knit', 'group', 'nearly', 'omnipotent', 'consisting', 'novel', 'alleged', 'weird', 'anton', 'wilson', 'shea', 'conspiracies', 'competing', \"tolkein's\", 'canterbury', 'author', 'canturbury', 'write', \"plato's\", 'allegory', 'cave', 'project', 'gutenberg', 'archive', 'thousands', 'volumes', 'iliad', 'odyssey', 'cool', 'hans', 'moravec', 'older', 'cyberpunk', 'newer', 'expect', \"wasn't\", 'catcher', 'rye', \"russia's\", 'writers', 'philip', 'k', 'dick', 'valis', 'castle', 'movies', 'couple', 'inspirational', 'novels', 'ones', \"weren't\", 'liking', 'poet', 'truly', 'reference', 'commonly', 'occurring', 'literary', 'technical', 'proposals', 'loved', 'trip', 'master', 'victorian', 'foundation', 'ideas', 'isaac', 'janet', 'lem', 'giant', 'sufficiently', 'adapt', 'wester', 'fyodor', 'dostoyevsky', 'j', 'tolkein', 'mary', 'shelley', 'invest', 'casino', 'recommend', 'buying', 'margin', 'lawyer', 'tips', 'mutual', 'funds', 'unless', 'wealthy', 'indvidual', 'alone', 'beat', 'actions', 'currency', 'standard', 'pieces', 'silver', 'copper', 'nickel', 'stamped', 'authority', 'medium', 'measure', 'substance', 'article', 'notes', 'checks', 'shares', 'volume', 'deals', 'consumption', 'wealth', 'related', 'labor', 'finance', 'taxation', 'technically', 'allocation', 'scarcity', 'produce', 'fill', \"people's\", 'nobody', 'pays', 'expecting', 'raise', 'material', 'possessions', 'burn', '3000', 'month', 'anymore', 'stockholders', 'compliment', 'grammatical', 'released', '2002', 'comic', 'film', 'female', 'ruby', 'edition', 'heuristic', 'algorithmic', 'monster', 'endangers', 'japanese', 'cities', 'york', 'peter', 'parker', 'logique', 'heuristique', 'algorithmique', 'flaws', 'famous', 'marx', 'observations', 'ideally', 'representative', 'global', 'promoting', 'enviornmental', 'activism', 'land', 'factories', 'railroads', 'privately', 'owned', 'operated', 'profit', 'originally', 'fully', 'competitive', 'their', 'volvos', 'theories', 'operation', 'private', 'members', 'sharing', 'products', 'established', 'administration', 'nation', 'district', 'governed', 'sociopolitical', 'movement', 'advocating', 'resolution', 'class', 'conflict', 'bringing', 'classless', \"person's\", 'honor', 'reputation', 'challenged', 'discredited', 'perfectly', 'understandable', 'amendemnt', 'violence', '2nd', 'amendment', 'andrew', 'jackson', 'happily', \"couldn't\", 'bothered', 'accused', 'overdo', 'kiss', 'derangement', 'condition', 'feels', 'stomach', 'night', 'social', 'compared', 'pack', 'yep', 'behave', 'socially', 'unacceptable', 'appearance', 'along', 'sounds', 'fighting', 'learning', 'whoever', 'job', 'albert', 'einstein', 'uptight', 'tend', 'resisting', 'describe', 'spending', 'productively', 'shortcuts', 'diagnosed', 'failed', 'relationship', 'lost', 'parenting', 'skills', 'improvement', 'students', 'last', 'living', 'wits', 'liar', 'bathe', 'believe', 'irritates', 'counseling', 'working', 'oxymoron', 'upset', 'jocks', 'guiltier', 'physicist', 'entropy', 'conservation', 'cancer', 'inverse', 'transformation', 'forms', 'governing', 'conversions', 'mixing', 'chemicals', 'crystals', 'molecules', 'mole', 'numerical', 'six', 'zero', 'twenty', 'third', 'ultrasonic', 'waves', 'medical', 'diagnosis', 'therapy', 'surgery', 'fancy', 'applied', 'biology', 'roman', 'mythology', 'goddess', 'beauty', 'identified', 'greek', 'aphrodite', 'brightest', 'sixth', 'largest', 'solar', 'dense', 'atmosphere', 'carbon', 'dioxide', 'surface', 'temperature', 'fishes', 'h', 'v', 'recall', 'measured', 'direction', 'prograssion', 'wave', 'characterized', 'phase', 'looked', 'scientific', 'bacteria', 'diseases', 'caused', 'invitation', 'burial', 'force', 'photons', 'attracts', 'attracted', '93', '250', '000', 'average', 'glove', 'snowboarding', 'tall', 'without', 'gene', 'rawhide', 'covered', 'opposing', 'nine', 'four', 'bases', 'forming', 'diamond', 'shaped', 'goal', 'moved', 'chiefly', 'kicking', 'hands', 'arms', 'centre', 'rectangular', '22', 'yard', 'pitch', 'wicket', 'stumps', 'sited', 'coordination', 'hoops', 'baby', 'george', 'herman', 'ruth', 'babe', 'maradona', 'sinsemillia', 'barcelona', 'team', 'attack', 'barca', 'par', 'dont', 'richard', 'nixon', '1963', 'soviet', 'union', 'sputnik', 'gyroscope', 'edwin', 'andromeda', 'kingdom', 'britain', 'europe', 'echolocation']\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "for word in tokenizer.word_index:\n",
    "  vocab.append(word)\n",
    "print(vocab)\n",
    "def tokenize(sentences):\n",
    "  tokens_list = []\n",
    "  vocabulary = []\n",
    "  for sentence in sentences:\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    tokens = sentence.split()\n",
    "    vocabulary += tokens\n",
    "    tokens_list.append(tokens)\n",
    "  return tokens_list, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9vKhieIwCo7J",
    "outputId": "e97b4a74-7384-478c-d4ae-082513257107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10, 7, 269], [10, 7, 269], [11, 3, 346], [11, 3, 346], [11, 3, 346], [11, 3, 270], [11, 3, 270], [11, 3, 270], [11, 3, 270], [10, 158, 11, 3, 195, 17], [10, 158, 11, 3, 195, 17], [3, 196, 31, 226], [3, 196, 31, 226], [3, 11, 33, 132, 471, 472], [3, 11, 33, 132, 471, 472], [3, 11, 13, 133], [3, 11, 13, 133], [3, 11, 13, 133], [3, 11, 13, 227, 99], [3, 11, 13, 227, 99], [3, 11, 13, 227, 99], [3, 11, 13, 227, 99], [3, 11, 13, 227, 99], [3, 11, 133], [3, 11, 133], [3, 11, 133], [3, 12, 13, 64, 55, 99], [3, 23, 13, 473], [3, 23, 13, 473], [3, 23, 13, 228], [3, 23, 13, 228], [474, 229], [474, 229], [67, 271], [67, 62, 68], [67], [67, 11, 475], [67, 11, 13, 347, 9, 230], [67, 11, 13, 347, 9, 230], [67, 11, 13, 347, 9, 230], [272], [16, 7, 4, 36], [16, 7, 4, 36], [26, 69, 3, 348], [26, 69, 3, 348], [26, 69, 3, 782], [26, 69, 3, 68], [26, 12, 3, 68], [26, 12, 3, 68], [26, 12, 3, 68], [10, 7, 4, 91, 78], [10, 7, 4, 91, 78], [10, 7, 4, 91, 171], [10, 7, 4, 273], [10, 7, 4, 273], [10, 7, 4, 476], [10, 7, 4, 477, 478], [10, 7, 28, 78, 134], [10, 7, 28, 78, 134], [10, 7, 28, 231], [10, 7, 28, 231], [10, 7, 28, 70, 274, 158], [10, 7, 28, 70, 274, 158], [10, 7, 28, 70, 479], [10, 7, 28, 783], [10, 7, 28, 784, 785], [10, 7, 16, 31, 9, 32, 4, 78], [10, 7, 16, 31, 9, 32, 4, 78], [10, 7, 16, 31, 172, 4, 36], [10, 7, 16, 31, 172, 4, 36], [10, 173, 159], [10, 173, 159], [10, 480, 8, 36], [10, 480, 8, 36, 11, 3], [10, 197, 8, 36], [10, 197, 8, 160], [5, 481, 19, 3, 68], [5, 481, 19, 3, 68], [5, 12, 13, 174, 9, 68], [5, 12, 13, 174, 9, 68], [5, 12, 13, 174, 9, 68], [7, 16, 349, 17, 6, 36], [7, 16, 349, 17, 6, 36], [7, 16, 349, 17, 6, 36], [7, 16, 232, 19, 3, 11, 4, 36, 198], [69, 3, 68], [69, 3, 111, 68], [23, 3, 348], [23, 3, 482], [23, 3, 482], [23, 3, 228], [23, 3, 228], [23, 3, 68], [23, 3, 68], [23, 3, 233], [23, 3, 483], [23, 3, 483], [23, 3, 234], [23, 3, 786], [29, 23, 5, 175, 28, 787], [69, 3, 68], [10, 12, 3, 31, 9, 12], [10, 12, 3, 31, 9, 12], [11, 3, 475], [37, 11, 3], [10, 11, 28, 484], [10, 11, 28, 70, 485], [10, 11, 28, 484], [10, 7, 28, 135], [10, 7, 28, 135], [10, 7, 28, 70, 135], [10, 23, 3, 92], [56, 136, 3, 92, 235], [10, 7, 28, 350], [10, 7, 28, 350], [351, 11, 3, 63], [351, 11, 3], [12, 3, 18, 55, 352], [12, 3, 18, 55, 352], [37, 7, 28, 486], [37, 7, 28, 487], [37, 7, 28, 788], [10, 7, 28, 353], [10, 7, 28, 353], [10, 7, 4, 36], [10, 7, 4, 275, 36], [37, 236, 93], [10, 58, 6, 176, 36], [10, 7, 4, 789], [10, 7, 33, 173, 199], [52, 7, 143, 354, 38, 488], [200, 100, 36, 790], [37, 489, 275, 93], [29, 79, 4, 36, 101], [3, 11, 490], [3, 11, 355], [3, 11, 122, 112], [3, 11, 237], [3, 11, 122, 161], [3, 69, 32, 238], [3, 62, 32, 356], [3, 23, 13, 34], [3, 23, 13, 123], [18, 3, 791], [18, 3, 111, 177], [79, 19, 64, 3], [79, 16, 64, 3, 112], [144], [10, 7, 28, 201], [10, 7, 28, 276], [10, 113, 3, 112], [10, 113, 3, 491], [10, 113, 3, 80], [10, 12, 3, 178], [10, 12, 3, 162], [5, 18, 102], [5, 20, 492], [163, 357], [29, 145], [29, 23, 5, 792, 3], [12, 13, 178], [12, 13, 230], [12, 3, 34, 358], [12, 3, 34, 102], [12, 3, 34, 239], [12, 3, 111, 24, 80], [12, 3, 111, 24, 493], [12, 3, 111, 24, 359], [12, 3, 111, 24, 145], [12, 3, 162, 240], [12, 3, 24, 793], [12, 3, 24, 80], [40, 16, 7, 13], [21, 15, 35, 360], [21, 15, 35, 28, 494], [11, 3, 356], [6, 81], [11, 3, 794], [11, 3, 237], [11, 3, 795], [11, 3, 796], [11, 3, 112], [12, 3, 241], [12, 3, 241], [179], [11, 3, 495, 33, 242, 496], [11, 3, 495, 33, 242, 496], [56, 23, 3, 13, 92], [71, 3, 59, 92, 235, 10, 94, 3, 92], [12, 3, 497, 3, 59, 92, 235], [23, 4, 78, 24, 797], [5, 31, 798, 12, 3], [10, 12, 67, 202, 9, 799], [69, 67, 111, 32, 361, 9, 92], [10, 7, 124, 9, 92], [56, 41, 3, 92], [12, 3, 92], [12, 3, 92], [12, 3, 92], [12, 3, 57, 103], [12, 3, 57, 103], [12, 3, 57, 103], [12, 3, 57, 103], [10, 7, 277], [21, 15, 35, 103], [21, 15, 35, 103], [21, 15, 35, 103], [21, 15, 35, 103], [21, 15, 103], [146], [146], [146], [146], [146], [72, 21, 146, 9, 243], [72, 21, 146, 9, 243], [72, 21, 146, 9, 243], [72, 21, 146, 9, 243], [278], [147], [498], [278], [147, 29, 7, 16, 148], [147, 29, 7, 16, 148], [147, 29, 7, 16, 148], [147, 29, 7, 16, 148], [147, 29, 7, 16, 148], [147, 29, 7, 16, 148], [29, 11, 3, 203], [29, 11, 3, 203], [29, 11, 3, 203], [161, 9, 362, 3], [29, 12, 3, 12], [29, 12, 3, 12], [147, 161, 9, 362, 3], [16, 7, 4, 499, 9, 362, 3], [500, 8, 6, 363, 9, 3], [500, 8, 6, 363, 9, 3], [204, 95], [204, 95], [204, 95], [204, 95], [204, 95], [29, 7, 28, 800], [21, 15, 35, 6, 364, 501, 279], [12, 3, 57, 35, 6, 364, 501, 279], [10, 7, 149], [10, 197, 8, 149], [11, 3, 244, 17, 149], [801, 149], [37, 236, 6, 802], [37, 236, 6, 803, 365], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 4, 30], [21, 15, 100, 502], [12, 57, 55, 502], [21, 15, 4, 30], [21, 15, 4, 30], [10, 7, 804], [10, 7, 6, 805], [10, 7, 6, 503], [10, 7, 6, 503], [10, 7, 366], [10, 7, 367], [10, 7, 367], [37, 205, 366], [37, 7, 504, 505], [37, 7, 506, 368], [37, 7, 507, 508], [18, 3, 82, 806], [18, 3, 82, 509], [18, 3, 111, 82, 4, 206], [18, 3, 111, 82, 4, 206], [18, 3, 111, 82, 4, 206], [18, 3, 82, 150, 369], [18, 3, 82, 807], [510, 808], [10, 7, 245, 809], [511, 512], [511, 512], [810, 811], [812, 813], [12, 513, 151, 8, 370, 371], [12, 513, 151, 8, 370, 371], [372, 373], [372, 373], [372, 373], [56, 12, 3, 31, 814], [56, 7, 6, 815, 8, 280, 514], [374, 375, 376], [374, 375, 376], [515, 516], [515, 516], [281], [281], [281], [281], [37, 205, 6, 816], [37, 205, 6, 517], [37, 205, 509], [3, 24, 817], [73, 96], [73, 96], [73, 96], [73, 96], [73, 96], [73, 96], [73, 96], [73, 96], [818, 518], [10, 7, 4, 282], [10, 7, 125], [10, 7, 6, 73, 96], [10, 7, 6, 73, 96], [10, 7, 6, 73, 96], [10, 7, 28, 70, 519], [10, 7, 28, 70, 519], [10, 7, 377], [10, 7, 377], [10, 7, 377], [5, 24, 73], [125], [29, 48, 12, 3, 378], [29, 48, 12, 3, 378], [29, 48, 12, 3, 378], [29, 48, 12, 3, 819], [29, 48, 125, 12, 3, 18], [29, 48, 125], [29, 48, 125], [520, 282], [37, 7, 6, 820, 8, 4, 821], [3, 196, 31, 83], [3, 196, 31, 822], [18, 3, 379, 823, 824], [825, 380], [26, 72, 381], [10, 7, 380], [10, 7, 381], [10, 7, 521], [10, 7, 826], [10, 79, 83, 827, 39], [5, 828, 6, 829], [7, 83, 522, 28, 830], [7, 83, 831], [7, 83, 161], [7, 83, 832], [7, 83, 523], [7, 83], [37, 7, 524], [37, 7, 833, 164], [382, 8, 6, 383], [834, 835, 836, 83], [12, 3, 49, 83], [12, 3, 57, 83], [18, 3, 82, 6, 837], [10, 7, 4, 384], [10, 7, 838], [10, 7, 839], [10, 7, 840], [10, 7, 384], [10, 7, 525], [10, 7, 526], [5, 12, 13, 31, 207], [5, 12, 13, 31, 207], [12, 3, 31, 207], [56, 207], [37, 58, 6, 176, 526, 385], [37, 7, 6, 527], [37, 7, 6, 527], [207], [841, 15, 208, 3, 4, 209], [3, 11, 842], [3, 11, 843], [3, 11, 386], [3, 11, 386], [3, 11, 844], [3, 11, 33, 387], [3, 11, 33, 845], [3, 11, 33, 528, 846], [3, 11, 847], [3, 11, 848], [3, 11, 529], [3, 11, 849], [3, 11, 850], [3, 11, 851], [3, 11, 210], [3, 11, 852], [3, 11, 388], [3, 11, 388], [3, 11, 6, 853], [3, 11, 180], [3, 11, 854], [3, 11, 855], [3, 11, 856], [3, 11, 530], [3, 11, 857], [3, 11, 13, 531], [3, 11, 13, 389, 9], [3, 11, 13, 283, 858], [3, 11, 13, 859], [3, 11, 13, 4, 124], [3, 11, 13, 4, 164], [3, 11, 13, 860], [3, 11, 13, 532], [3, 11, 284], [3, 11, 284], [3, 11, 533], [3, 11, 534], [3, 11, 861], [3, 11, 285, 862], [3, 11, 285], [3, 11, 863], [3, 11, 246, 864], [3, 11, 535], [3, 11, 865], [3, 11, 536], [3, 11, 536], [3, 11, 866], [867, 11, 868], [3, 11, 4, 869], [3, 11, 4, 870], [3, 11, 4, 537], [3, 11, 4, 871], [3, 11, 4, 872], [3, 11, 4, 87, 286], [3, 11, 4, 87, 390], [3, 11, 4, 87, 873], [3, 11, 4, 87, 874], [3, 11, 4, 87, 875], [3, 11, 4, 87, 876], [3, 11, 4, 877], [3, 11, 4, 878], [3, 11, 4, 879], [3, 11, 4, 880], [3, 11, 4, 391], [3, 11, 881], [3, 11, 882], [3, 11, 538], [3, 11, 539], [3, 11, 883], [3, 11, 391], [3, 11, 884], [3, 104, 9, 540, 16], [3, 24, 80, 53, 15], [3, 202, 4, 885], [3, 202, 9, 101, 541], [3, 59, 18, 886], [3, 64, 15, 34, 31, 5, 20], [3, 64, 15, 80], [3, 64, 15, 145], [3, 530], [3, 392, 65, 31], [3, 12, 13, 137, 114, 542], [3, 887, 95], [3, 62, 34, 543], [3, 62, 24, 65], [3, 62, 888, 95], [3, 62, 137, 65], [3, 889], [3, 393, 31, 4, 890], [3, 394, 544], [3, 394, 891], [3, 138, 15, 80], [10, 11, 6, 545, 8, 287], [10, 892, 79, 4, 893, 546], [10, 7, 4, 247], [10, 7, 287], [10, 7, 248], [10, 7, 894], [10, 7, 895, 547, 135], [10, 7, 896], [10, 7, 897], [10, 7, 249], [10, 7, 898], [10, 7, 899], [10, 7, 548], [10, 7, 548], [10, 7, 247], [10, 7, 900], [10, 7, 549], [10, 7, 549], [66, 11, 46, 6, 165, 247], [29, 181, 7, 6, 211], [29, 181, 7, 6, 211], [29, 181, 7, 6, 288], [29, 181, 7, 6, 288], [12, 3, 57, 248], [12, 3, 182, 287], [248], [6, 165, 247], [21, 15, 35, 249], [21, 15, 35, 249], [289, 550, 17, 901, 212, 6], [71, 3, 11, 902, 903, 551], [10, 7, 250], [10, 213], [10, 7, 212], [10, 7, 213], [5, 177, 212], [5, 166, 213], [5, 166, 290], [10, 7, 290], [5, 166, 904], [12, 3, 166, 213], [12, 3, 166, 250], [12, 3, 57, 905], [31, 250], [11, 3, 4, 552], [37, 7, 6, 553, 212, 554], [37, 7, 6, 183, 213, 554], [21, 15, 35, 212], [52, 7, 28, 906, 213, 907], [37, 58, 6, 908, 385, 8, 6, 291, 292], [10, 550, 58, 385, 395, 909, 910, 911], [6, 396, 555, 58, 4, 912, 913, 914, 251, 10, 126, 915, 279, 916, 39, 917, 17, 918, 556], [10, 58, 6, 200, 8, 6, 176, 132, 293, 919], [4, 920, 557, 17, 52, 6, 921, 8, 114, 922, 7, 923, 42, 924, 38, 925, 8, 6, 926, 7, 294, 10], [6, 558, 396, 927, 928, 139, 295, 293, 559, 17, 929, 7, 560, 561, 10, 364, 930], [10, 7, 6, 200, 8, 6, 931, 932, 296, 9, 6, 933, 184], [934, 562, 6, 935, 7, 6, 936, 937, 8, 10, 563], [6, 564, 565, 6, 938, 397, 6, 564, 939, 7, 4, 398, 8, 6, 940, 565, 8, 10, 941], [942, 175, 4, 99, 943, 9, 944, 9, 945, 6, 350, 14, 946, 8, 947, 948]]\n",
      "22\n",
      "[[ 10   7 269 ...   0   0   0]\n",
      " [ 10   7 269 ...   0   0   0]\n",
      " [ 11   3 346 ...   0   0   0]\n",
      " ...\n",
      " [934 562   6 ...   0   0   0]\n",
      " [  6 564 565 ...   0   0   0]\n",
      " [942 175   4 ...   0   0   0]]\n",
      "(564, 22) 22\n"
     ]
    }
   ],
   "source": [
    "#encoder_input_data\n",
    "tokenized_questions = tokenizer.texts_to_sequences( questions )\n",
    "print(tokenized_questions)\n",
    "maxlen_questions = max( [len(x) for x in tokenized_questions ] )\n",
    "print(maxlen_questions)\n",
    "padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions, maxlen = maxlen_questions, padding = 'post')\n",
    "print(padded_questions)\n",
    "encoder_input_data = np.array(padded_questions)\n",
    "print(encoder_input_data.shape, maxlen_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AJo7WPjLCo-q",
    "outputId": "28b5e209-5389-4313-f3cd-f5451fa8c519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 74) 74\n"
     ]
    }
   ],
   "source": [
    "# decoder_input_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
    "maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n",
    "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
    "decoder_input_data = np.array( padded_answers )\n",
    "print( decoder_input_data.shape , maxlen_answers )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ccY0wWdRCpCa",
    "outputId": "07877cda-7e07-42b2-bb7e-772d118a3cf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]]\n",
      "(564, 74, 1894)\n"
     ]
    }
   ],
   "source": [
    "# decoder_output_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
    "for i in range(len(tokenized_answers)) :\n",
    "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
    "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
    "onehot_answers = utils.to_categorical( padded_answers , VOCAB_SIZE )\n",
    "decoder_output_data = np.array( onehot_answers )\n",
    "print( decoder_output_data.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-D53pyucPCnk"
   },
   "source": [
    "# Step 4: Defining Encoder Decoder Model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "colab_type": "code",
    "id": "W3YjCFDwPRVN",
    "outputId": "7bc112a0-6945-4100-e8d9-3bc5691797e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                  </span><span style=\"font-weight: bold\"> Output Shape              </span><span style=\"font-weight: bold\">         Param # </span><span style=\"font-weight: bold\"> Connected to               </span>\n",
       "\n",
       " input_layer_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                          \n",
       "\n",
       " input_layer_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                          \n",
       "\n",
       " embedding_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">484,864</span>  input_layer_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " not_equal_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  input_layer_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " embedding_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">484,864</span>  input_layer_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " lstm_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,               <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span>  embedding_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        \n",
       "                                <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                          not_equal_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       "\n",
       " lstm_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,           <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span>  embedding_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        \n",
       "                                <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                          lstm_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],             \n",
       "                                                                            lstm_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]              \n",
       "\n",
       " dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1894</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">486,758</span>  lstm_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_layer_29 (\u001b[38;5;33mInputLayer\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)                               \u001b[38;5;34m0\u001b[0m  -                          \n",
       "\n",
       " input_layer_30 (\u001b[38;5;33mInputLayer\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m)                               \u001b[38;5;34m0\u001b[0m  -                          \n",
       "\n",
       " embedding_18 (\u001b[38;5;33mEmbedding\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m256\u001b[0m)                    \u001b[38;5;34m484,864\u001b[0m  input_layer_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " not_equal_8 (\u001b[38;5;33mNotEqual\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)                               \u001b[38;5;34m0\u001b[0m  input_layer_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " embedding_19 (\u001b[38;5;33mEmbedding\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m256\u001b[0m)                    \u001b[38;5;34m484,864\u001b[0m  input_layer_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " lstm_26 (\u001b[38;5;33mLSTM\u001b[0m)                 [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,               \u001b[38;5;34m525,312\u001b[0m  embedding_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        \n",
       "                                \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]                          not_equal_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       "\n",
       " lstm_27 (\u001b[38;5;33mLSTM\u001b[0m)                 [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,           \u001b[38;5;34m525,312\u001b[0m  embedding_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        \n",
       "                                \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]                          lstm_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],             \n",
       "                                                                            lstm_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]              \n",
       "\n",
       " dense_11 (\u001b[38;5;33mDense\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m1894\u001b[0m)                   \u001b[38;5;34m486,758\u001b[0m  lstm_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,110</span> (9.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,507,110\u001b[0m (9.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,110</span> (9.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,507,110\u001b[0m (9.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=( maxlen_questions , ))\n",
    "encoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 256, mask_zero=True ) (encoder_inputs)\n",
    "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 256 , return_state=True )( encoder_embedding )\n",
    "\n",
    "encoder_states = [ state_h , state_c ]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=( maxlen_answers ,  ))\n",
    "decoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 256 , mask_zero=True) (decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM( 256 , return_state=True , return_sequences=True )\n",
    "\n",
    "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
    "\n",
    "decoder_dense = tf.keras.layers.Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax ) \n",
    "output = decoder_dense ( decoder_outputs )\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming 'decoder_output_sequences' is already a list of word indices\n",
    "# decoder_output_data = pad_sequences(decoder_output_sequences, maxlen=maxlen_answers, padding='post')\n",
    "\n",
    "# # Ensure decoder_output_data is a 2D array with shape (batch_size, sequence_length)\n",
    "# print(f'Decoder Output Shape: {decoder_output_data.shape}')  # Should print (batch_size, sequence_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wVfSormAPb3w"
   },
   "source": [
    "# Step 5: Training the Model\n",
    "\n",
    "We train the model for a number of epochs with RMSprop optimizer and categorical_crossentropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OHlqQq64PYTH",
    "outputId": "c477c08f-55e4-41ac-b8b7-1973aa38f48a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 2.1070\n",
      "Epoch 2/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 2.0684\n",
      "Epoch 3/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 2.0565\n",
      "Epoch 4/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 2.0631\n",
      "Epoch 5/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 1.9525\n",
      "Epoch 6/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 2.0205\n",
      "Epoch 7/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 1.9732\n",
      "Epoch 8/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 2.0064\n",
      "Epoch 9/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 1.9931\n",
      "Epoch 10/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 1.9445\n",
      "Epoch 11/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 1.9153\n",
      "Epoch 12/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 1.8868\n",
      "Epoch 13/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 1.8929\n",
      "Epoch 14/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 1.8419\n",
      "Epoch 15/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 1.8509\n",
      "Epoch 16/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 1.8481\n",
      "Epoch 17/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 1.8071\n",
      "Epoch 18/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 1.8427\n",
      "Epoch 19/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 1.7813\n",
      "Epoch 20/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 1.7516\n",
      "Epoch 21/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 215ms/step - loss: 1.7607\n",
      "Epoch 22/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 1.7518\n",
      "Epoch 23/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 1.7125\n",
      "Epoch 24/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 1.6797\n",
      "Epoch 25/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 1.6711\n",
      "Epoch 26/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 1.6816\n",
      "Epoch 27/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 1.6170\n",
      "Epoch 28/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 1.6170\n",
      "Epoch 29/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 1.6047\n",
      "Epoch 30/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 1.5676\n",
      "Epoch 31/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 1.6007\n",
      "Epoch 32/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 1.5768\n",
      "Epoch 33/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 199ms/step - loss: 1.5720\n",
      "Epoch 34/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 1.5463\n",
      "Epoch 35/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 1.5214\n",
      "Epoch 36/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 1.5176\n",
      "Epoch 37/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 1.5272\n",
      "Epoch 38/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 1.4665\n",
      "Epoch 39/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 1.5258\n",
      "Epoch 40/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 1.4629\n",
      "Epoch 41/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 1.4497\n",
      "Epoch 42/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 1.4408\n",
      "Epoch 43/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 1.4012\n",
      "Epoch 44/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 245ms/step - loss: 1.4156\n",
      "Epoch 45/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 1.3812\n",
      "Epoch 46/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 1.3908\n",
      "Epoch 47/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 1.3340\n",
      "Epoch 48/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 1.4061\n",
      "Epoch 49/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 1.3150\n",
      "Epoch 50/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 226ms/step - loss: 1.3348\n",
      "Epoch 51/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 224ms/step - loss: 1.2768\n",
      "Epoch 52/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 242ms/step - loss: 1.3144\n",
      "Epoch 53/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - loss: 1.2850\n",
      "Epoch 54/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 245ms/step - loss: 1.2684\n",
      "Epoch 55/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 248ms/step - loss: 1.2558\n",
      "Epoch 56/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 267ms/step - loss: 1.2210\n",
      "Epoch 57/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 226ms/step - loss: 1.2293\n",
      "Epoch 58/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 215ms/step - loss: 1.2167\n",
      "Epoch 59/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 206ms/step - loss: 1.2127\n",
      "Epoch 60/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 248ms/step - loss: 1.2117\n",
      "Epoch 61/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 240ms/step - loss: 1.1910\n",
      "Epoch 62/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 233ms/step - loss: 1.2095\n",
      "Epoch 63/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 246ms/step - loss: 1.1848\n",
      "Epoch 64/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 242ms/step - loss: 1.1357\n",
      "Epoch 65/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 242ms/step - loss: 1.1588\n",
      "Epoch 66/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 235ms/step - loss: 1.1213\n",
      "Epoch 67/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 280ms/step - loss: 1.1265\n",
      "Epoch 68/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 276ms/step - loss: 1.0884\n",
      "Epoch 69/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 262ms/step - loss: 1.0891\n",
      "Epoch 70/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 241ms/step - loss: 1.0763\n",
      "Epoch 71/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 205ms/step - loss: 1.0776\n",
      "Epoch 72/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 208ms/step - loss: 1.0486\n",
      "Epoch 73/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 1.0372\n",
      "Epoch 74/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 1.0359\n",
      "Epoch 75/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 1.0046\n",
      "Epoch 76/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 224ms/step - loss: 1.0160\n",
      "Epoch 77/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - loss: 0.9917\n",
      "Epoch 78/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 1.0451\n",
      "Epoch 79/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.9771\n",
      "Epoch 80/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.9734\n",
      "Epoch 81/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 205ms/step - loss: 0.9534\n",
      "Epoch 82/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.9425\n",
      "Epoch 83/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 215ms/step - loss: 0.9420\n",
      "Epoch 84/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 213ms/step - loss: 0.9213\n",
      "Epoch 85/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.9194\n",
      "Epoch 86/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 234ms/step - loss: 0.8840\n",
      "Epoch 87/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 206ms/step - loss: 0.9092\n",
      "Epoch 88/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.8813\n",
      "Epoch 89/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.8863\n",
      "Epoch 90/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.8447\n",
      "Epoch 91/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.8534\n",
      "Epoch 92/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.8479\n",
      "Epoch 93/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.8405\n",
      "Epoch 94/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.8311\n",
      "Epoch 95/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.7966\n",
      "Epoch 96/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.8159\n",
      "Epoch 97/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.8013\n",
      "Epoch 98/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.7633\n",
      "Epoch 99/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.7622\n",
      "Epoch 100/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.7516\n",
      "Epoch 101/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - loss: 0.7635\n",
      "Epoch 102/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.7532\n",
      "Epoch 103/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.7522\n",
      "Epoch 104/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.7427\n",
      "Epoch 105/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.7255\n",
      "Epoch 106/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 252ms/step - loss: 0.7266\n",
      "Epoch 107/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 225ms/step - loss: 0.7032\n",
      "Epoch 108/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.7010\n",
      "Epoch 109/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.6964\n",
      "Epoch 110/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 239ms/step - loss: 0.7011\n",
      "Epoch 111/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 251ms/step - loss: 0.6768\n",
      "Epoch 112/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 200ms/step - loss: 0.6554\n",
      "Epoch 113/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.6646\n",
      "Epoch 114/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 203ms/step - loss: 0.6416\n",
      "Epoch 115/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.6571\n",
      "Epoch 116/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.6564\n",
      "Epoch 117/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 218ms/step - loss: 0.6511\n",
      "Epoch 118/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 245ms/step - loss: 0.6108\n",
      "Epoch 119/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 244ms/step - loss: 0.6213\n",
      "Epoch 120/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.6055\n",
      "Epoch 121/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.6176\n",
      "Epoch 122/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.5780\n",
      "Epoch 123/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 278ms/step - loss: 0.5844\n",
      "Epoch 124/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 226ms/step - loss: 0.5753\n",
      "Epoch 125/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 230ms/step - loss: 0.5812\n",
      "Epoch 126/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.5724\n",
      "Epoch 127/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 217ms/step - loss: 0.5771\n",
      "Epoch 128/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.5534\n",
      "Epoch 129/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - loss: 0.5514\n",
      "Epoch 130/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.5510\n",
      "Epoch 131/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.5524\n",
      "Epoch 132/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.5312\n",
      "Epoch 133/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.5445\n",
      "Epoch 134/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.5164\n",
      "Epoch 135/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.5332\n",
      "Epoch 136/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.5060\n",
      "Epoch 137/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.5000\n",
      "Epoch 138/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.5008\n",
      "Epoch 139/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.4795\n",
      "Epoch 140/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.4858\n",
      "Epoch 141/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.4739\n",
      "Epoch 142/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.4778\n",
      "Epoch 143/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.4622\n",
      "Epoch 144/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.4545\n",
      "Epoch 145/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - loss: 0.4660\n",
      "Epoch 146/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.4416\n",
      "Epoch 147/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 208ms/step - loss: 0.4522\n",
      "Epoch 148/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.4329\n",
      "Epoch 149/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 206ms/step - loss: 0.4206\n",
      "Epoch 150/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.4313\n",
      "Epoch 151/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 218ms/step - loss: 0.4224\n",
      "Epoch 152/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 262ms/step - loss: 0.3980\n",
      "Epoch 153/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 217ms/step - loss: 0.4333\n",
      "Epoch 154/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 236ms/step - loss: 0.4151\n",
      "Epoch 155/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 233ms/step - loss: 0.4157\n",
      "Epoch 156/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.3982\n",
      "Epoch 157/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.4100\n",
      "Epoch 158/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.4076\n",
      "Epoch 159/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.3849\n",
      "Epoch 160/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.3846\n",
      "Epoch 161/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.3665\n",
      "Epoch 162/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - loss: 0.3771\n",
      "Epoch 163/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 208ms/step - loss: 0.3733\n",
      "Epoch 164/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 212ms/step - loss: 0.3666\n",
      "Epoch 165/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 208ms/step - loss: 0.3753\n",
      "Epoch 166/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.3636\n",
      "Epoch 167/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.3489\n",
      "Epoch 168/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - loss: 0.3573\n",
      "Epoch 169/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.3474\n",
      "Epoch 170/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.3411\n",
      "Epoch 171/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.3385\n",
      "Epoch 172/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.3319\n",
      "Epoch 173/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 230ms/step - loss: 0.3365\n",
      "Epoch 174/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 255ms/step - loss: 0.3242\n",
      "Epoch 175/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 242ms/step - loss: 0.3166\n",
      "Epoch 176/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 278ms/step - loss: 0.3137\n",
      "Epoch 177/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 280ms/step - loss: 0.3112\n",
      "Epoch 178/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - loss: 0.3043\n",
      "Epoch 179/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.3133\n",
      "Epoch 180/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.3232\n",
      "Epoch 181/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.3073\n",
      "Epoch 182/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.2927\n",
      "Epoch 183/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.2965\n",
      "Epoch 184/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.2953\n",
      "Epoch 185/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.2887\n",
      "Epoch 186/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.3000\n",
      "Epoch 187/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.2896\n",
      "Epoch 188/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.2869\n",
      "Epoch 189/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.3027\n",
      "Epoch 190/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.2719\n",
      "Epoch 191/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.2734\n",
      "Epoch 192/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.2757\n",
      "Epoch 193/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.2695\n",
      "Epoch 194/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.2639\n",
      "Epoch 195/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 212ms/step - loss: 0.2763\n",
      "Epoch 196/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.2654\n",
      "Epoch 197/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.2602\n",
      "Epoch 198/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.2554\n",
      "Epoch 199/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.2658\n",
      "Epoch 200/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.2515\n",
      "Epoch 201/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.2470\n",
      "Epoch 202/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.2525\n",
      "Epoch 203/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.2446\n",
      "Epoch 204/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.2302\n",
      "Epoch 205/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.2387\n",
      "Epoch 206/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.2372\n",
      "Epoch 207/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.2319\n",
      "Epoch 208/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.2293\n",
      "Epoch 209/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.2293\n",
      "Epoch 210/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.2258\n",
      "Epoch 211/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.2217\n",
      "Epoch 212/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.2237\n",
      "Epoch 213/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.2168\n",
      "Epoch 214/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.2250\n",
      "Epoch 215/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.2146\n",
      "Epoch 216/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.2129\n",
      "Epoch 217/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.2203\n",
      "Epoch 218/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.2132\n",
      "Epoch 219/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.2085\n",
      "Epoch 220/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.2075\n",
      "Epoch 221/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.2015\n",
      "Epoch 222/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.2007\n",
      "Epoch 223/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.2078\n",
      "Epoch 224/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1955\n",
      "Epoch 225/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.1969\n",
      "Epoch 226/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1976\n",
      "Epoch 227/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.1984\n",
      "Epoch 228/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1912\n",
      "Epoch 229/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1887\n",
      "Epoch 230/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.1870\n",
      "Epoch 231/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.1899\n",
      "Epoch 232/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1844\n",
      "Epoch 233/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.1865\n",
      "Epoch 234/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1855\n",
      "Epoch 235/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.1768\n",
      "Epoch 236/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.1783\n",
      "Epoch 237/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1808\n",
      "Epoch 238/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.1813\n",
      "Epoch 239/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.1793\n",
      "Epoch 240/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.1774\n",
      "Epoch 241/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1660\n",
      "Epoch 242/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.1754\n",
      "Epoch 243/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1759\n",
      "Epoch 244/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1783\n",
      "Epoch 245/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1650\n",
      "Epoch 246/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.1647\n",
      "Epoch 247/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.1643\n",
      "Epoch 248/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1672\n",
      "Epoch 249/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.1640\n",
      "Epoch 250/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - loss: 0.1619\n",
      "Epoch 251/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.1653\n",
      "Epoch 252/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 205ms/step - loss: 0.1593\n",
      "Epoch 253/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 204ms/step - loss: 0.1631\n",
      "Epoch 254/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1599\n",
      "Epoch 255/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.1523\n",
      "Epoch 256/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1588\n",
      "Epoch 257/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.1530\n",
      "Epoch 258/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.1539\n",
      "Epoch 259/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.1584\n",
      "Epoch 260/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.1501\n",
      "Epoch 261/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.1441\n",
      "Epoch 262/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1480\n",
      "Epoch 263/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.1469\n",
      "Epoch 264/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.1439\n",
      "Epoch 265/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1510\n",
      "Epoch 266/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1515\n",
      "Epoch 267/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.1462\n",
      "Epoch 268/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.1453\n",
      "Epoch 269/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.1451\n",
      "Epoch 270/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.1492\n",
      "Epoch 271/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1488\n",
      "Epoch 272/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1412\n",
      "Epoch 273/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1399\n",
      "Epoch 274/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.1478\n",
      "Epoch 275/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1377\n",
      "Epoch 276/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.1382\n",
      "Epoch 277/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1342\n",
      "Epoch 278/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.1357\n",
      "Epoch 279/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1352\n",
      "Epoch 280/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.1416\n",
      "Epoch 281/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.1273\n",
      "Epoch 282/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1374\n",
      "Epoch 283/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1300\n",
      "Epoch 284/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.1314\n",
      "Epoch 285/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.1382\n",
      "Epoch 286/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.1307\n",
      "Epoch 287/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.1282\n",
      "Epoch 288/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1335\n",
      "Epoch 289/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1350\n",
      "Epoch 290/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.1291\n",
      "Epoch 291/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1269\n",
      "Epoch 292/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1305\n",
      "Epoch 293/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.1233\n",
      "Epoch 294/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.1246\n",
      "Epoch 295/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1258\n",
      "Epoch 296/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 220ms/step - loss: 0.1227\n",
      "Epoch 297/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 205ms/step - loss: 0.1295\n",
      "Epoch 298/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.1233\n",
      "Epoch 299/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.1290\n",
      "Epoch 300/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.1204\n",
      "Epoch 301/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1262\n",
      "Epoch 302/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - loss: 0.1201\n",
      "Epoch 303/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1186\n",
      "Epoch 304/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1194\n",
      "Epoch 305/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1202\n",
      "Epoch 306/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.1176\n",
      "Epoch 307/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.1097\n",
      "Epoch 308/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1134\n",
      "Epoch 309/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1177\n",
      "Epoch 310/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.1105\n",
      "Epoch 311/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.1161\n",
      "Epoch 312/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1179\n",
      "Epoch 313/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1169\n",
      "Epoch 314/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.1111\n",
      "Epoch 315/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 224ms/step - loss: 0.1134\n",
      "Epoch 316/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 211ms/step - loss: 0.1159\n",
      "Epoch 317/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.1172\n",
      "Epoch 318/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - loss: 0.1141\n",
      "Epoch 319/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.1226\n",
      "Epoch 320/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.1086\n",
      "Epoch 321/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.1171\n",
      "Epoch 322/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - loss: 0.1087\n",
      "Epoch 323/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.1171\n",
      "Epoch 324/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.1063\n",
      "Epoch 325/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.1078\n",
      "Epoch 326/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - loss: 0.1075\n",
      "Epoch 327/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.1089\n",
      "Epoch 328/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.1048\n",
      "Epoch 329/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 208ms/step - loss: 0.1089\n",
      "Epoch 330/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 206ms/step - loss: 0.1185\n",
      "Epoch 331/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.1007\n",
      "Epoch 332/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.1066\n",
      "Epoch 333/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - loss: 0.1053\n",
      "Epoch 334/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 206ms/step - loss: 0.1040\n",
      "Epoch 335/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.1061\n",
      "Epoch 336/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.1072\n",
      "Epoch 337/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 204ms/step - loss: 0.0999\n",
      "Epoch 338/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 203ms/step - loss: 0.1060\n",
      "Epoch 339/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 206ms/step - loss: 0.1066\n",
      "Epoch 340/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - loss: 0.1059\n",
      "Epoch 341/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.1034\n",
      "Epoch 342/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 205ms/step - loss: 0.0992\n",
      "Epoch 343/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.1097\n",
      "Epoch 344/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 206ms/step - loss: 0.0989\n",
      "Epoch 345/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 206ms/step - loss: 0.1035\n",
      "Epoch 346/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 205ms/step - loss: 0.1022\n",
      "Epoch 347/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - loss: 0.1062\n",
      "Epoch 348/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0973\n",
      "Epoch 349/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0997\n",
      "Epoch 350/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - loss: 0.0985\n",
      "Epoch 351/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 205ms/step - loss: 0.1020\n",
      "Epoch 352/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.1043\n",
      "Epoch 353/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0977\n",
      "Epoch 354/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - loss: 0.0973\n",
      "Epoch 355/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0979\n",
      "Epoch 356/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0997\n",
      "Epoch 357/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 208ms/step - loss: 0.1009\n",
      "Epoch 358/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.1005\n",
      "Epoch 359/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0993\n",
      "Epoch 360/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0947\n",
      "Epoch 361/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 201ms/step - loss: 0.0962\n",
      "Epoch 362/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 205ms/step - loss: 0.0963\n",
      "Epoch 363/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 202ms/step - loss: 0.0943\n",
      "Epoch 364/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - loss: 0.0982\n",
      "Epoch 365/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 203ms/step - loss: 0.0975\n",
      "Epoch 366/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0997\n",
      "Epoch 367/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 208ms/step - loss: 0.0929\n",
      "Epoch 368/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0975\n",
      "Epoch 369/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0936\n",
      "Epoch 370/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 205ms/step - loss: 0.0967\n",
      "Epoch 371/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 202ms/step - loss: 0.0955\n",
      "Epoch 372/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - loss: 0.0982\n",
      "Epoch 373/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 205ms/step - loss: 0.0970\n",
      "Epoch 374/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - loss: 0.0977\n",
      "Epoch 375/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0914\n",
      "Epoch 376/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 236ms/step - loss: 0.0946\n",
      "Epoch 377/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 265ms/step - loss: 0.0931\n",
      "Epoch 378/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 202ms/step - loss: 0.0996\n",
      "Epoch 379/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0898\n",
      "Epoch 380/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0928\n",
      "Epoch 381/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0945\n",
      "Epoch 382/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0925\n",
      "Epoch 383/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0903\n",
      "Epoch 384/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0920\n",
      "Epoch 385/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0863\n",
      "Epoch 386/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0888\n",
      "Epoch 387/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0935\n",
      "Epoch 388/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0950\n",
      "Epoch 389/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0880\n",
      "Epoch 390/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0966\n",
      "Epoch 391/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0880\n",
      "Epoch 392/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0846\n",
      "Epoch 393/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0829\n",
      "Epoch 394/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0913\n",
      "Epoch 395/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0893\n",
      "Epoch 396/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0902\n",
      "Epoch 397/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0881\n",
      "Epoch 398/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0918\n",
      "Epoch 399/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0866\n",
      "Epoch 400/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0968\n",
      "Epoch 401/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0854\n",
      "Epoch 402/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0905\n",
      "Epoch 403/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0838\n",
      "Epoch 404/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0819\n",
      "Epoch 405/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0872\n",
      "Epoch 406/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0918\n",
      "Epoch 407/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0857\n",
      "Epoch 408/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0856\n",
      "Epoch 409/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0847\n",
      "Epoch 410/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0825\n",
      "Epoch 411/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0896\n",
      "Epoch 412/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0876\n",
      "Epoch 413/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0827\n",
      "Epoch 414/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0844\n",
      "Epoch 415/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0841\n",
      "Epoch 416/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0823\n",
      "Epoch 417/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0778\n",
      "Epoch 418/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0899\n",
      "Epoch 419/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0872\n",
      "Epoch 420/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0859\n",
      "Epoch 421/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0800\n",
      "Epoch 422/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0797\n",
      "Epoch 423/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0828\n",
      "Epoch 424/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0833\n",
      "Epoch 425/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0854\n",
      "Epoch 426/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0849\n",
      "Epoch 427/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0888\n",
      "Epoch 428/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0851\n",
      "Epoch 429/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0832\n",
      "Epoch 430/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0798\n",
      "Epoch 431/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0804\n",
      "Epoch 432/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0923\n",
      "Epoch 433/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0815\n",
      "Epoch 434/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0861\n",
      "Epoch 435/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0823\n",
      "Epoch 436/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0837\n",
      "Epoch 437/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0802\n",
      "Epoch 438/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0819\n",
      "Epoch 439/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0849\n",
      "Epoch 440/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0798\n",
      "Epoch 441/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0778\n",
      "Epoch 442/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0840\n",
      "Epoch 443/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0809\n",
      "Epoch 444/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0784\n",
      "Epoch 445/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0840\n",
      "Epoch 446/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0806\n",
      "Epoch 447/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0788\n",
      "Epoch 448/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0769\n",
      "Epoch 449/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0776\n",
      "Epoch 450/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0770\n",
      "Epoch 451/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0793\n",
      "Epoch 452/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0796\n",
      "Epoch 453/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0821\n",
      "Epoch 454/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0741\n",
      "Epoch 455/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0796\n",
      "Epoch 456/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0782\n",
      "Epoch 457/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0797\n",
      "Epoch 458/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0758\n",
      "Epoch 459/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0788\n",
      "Epoch 460/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0775\n",
      "Epoch 461/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0793\n",
      "Epoch 462/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0764\n",
      "Epoch 463/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0806\n",
      "Epoch 464/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0731\n",
      "Epoch 465/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0738\n",
      "Epoch 466/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0793\n",
      "Epoch 467/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0774\n",
      "Epoch 468/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0760\n",
      "Epoch 469/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0814\n",
      "Epoch 470/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0737\n",
      "Epoch 471/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0773\n",
      "Epoch 472/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0781\n",
      "Epoch 473/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0800\n",
      "Epoch 474/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0751\n",
      "Epoch 475/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0837\n",
      "Epoch 476/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0782\n",
      "Epoch 477/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0761\n",
      "Epoch 478/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0743\n",
      "Epoch 479/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0770\n",
      "Epoch 480/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0814\n",
      "Epoch 481/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0748\n",
      "Epoch 482/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0739\n",
      "Epoch 483/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0762\n",
      "Epoch 484/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 208ms/step - loss: 0.0807\n",
      "Epoch 485/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0732\n",
      "Epoch 486/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0759\n",
      "Epoch 487/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0764\n",
      "Epoch 488/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0732\n",
      "Epoch 489/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0788\n",
      "Epoch 490/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0731\n",
      "Epoch 491/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0763\n",
      "Epoch 492/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0739\n",
      "Epoch 493/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0763\n",
      "Epoch 494/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0815\n",
      "Epoch 495/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0792\n",
      "Epoch 496/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0699\n",
      "Epoch 497/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0740\n",
      "Epoch 498/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0807\n",
      "Epoch 499/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0728\n",
      "Epoch 500/500\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 181ms/step - loss: 0.0724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Adding early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Fit the model\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_output_data, batch_size=50, epochs=500,callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1MIy1j9aVTo"
   },
   "source": [
    "# Step 6: Defining Inference Models\n",
    "\n",
    "Encoder Inference Model: Takes questions as input and outputs LSTM states (h and c)\n",
    "\n",
    "Decoder Inference Model: Takes in 2 inputs one are the LSTM states, second are the answer input sequences. it will o/p the answers for questions which fed to the encoder model and it's state values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MpLowS27cn8X"
   },
   "outputs": [],
   "source": [
    "def make_inference_models():\n",
    "    \n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = tf.keras.layers.Input(shape=( 256 ,))\n",
    "    decoder_state_input_c = tf.keras.layers.Input(shape=( 256 ,))\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding , initial_state=decoder_states_inputs)\n",
    "    \n",
    "    decoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    decoder_model = tf.keras.models.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model , decoder_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EwoYVsBTeYra"
   },
   "source": [
    "# Step 7: Talking with the Chatbot\n",
    "\n",
    "define a method str_to_tokens which converts str questions to Integer tokens with padding.\n",
    "\n",
    "1. First, we take a question as input and predict the state values using enc_model.\n",
    "2. We set the state values in the decoder's LSTM.\n",
    "3. Then, we generate a sequence which contains the <start> element.\n",
    "4. We input this sequence in the dec_model.\n",
    "5. We replace the <start> element with the element which was predicted by the dec_model and update the state values.\n",
    "6. We carry out the above steps iteratively till we hit the <end> tag or the maximum answer length.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oA7Yx45Li3wo"
   },
   "outputs": [],
   "source": [
    "# def str_to_tokens( sentence : str ):\n",
    "\n",
    "#     words = sentence.lower().split()\n",
    "#     tokens_list = list()\n",
    "  \n",
    "#     for word in words:\n",
    "#         tokens_list.append( tokenizer.word_index[ word ] ) \n",
    "#     return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')\n",
    "\n",
    "\n",
    "\n",
    "def str_to_tokens(sentence, maxlen=22):\n",
    "    tokens_list = []\n",
    "    words = sentence.lower().split()  # Ensure lowercase and tokenization\n",
    "    for word in words:\n",
    "        if word in tokenizer.word_index:\n",
    "            tokens_list.append(tokenizer.word_index[word])\n",
    "        else:\n",
    "            tokens_list.append(tokenizer.word_index.get('UNK', 0))  # Handle OOV words\n",
    "    # Pad the sequence to the required length (22 in this case)\n",
    "    return preprocessing.sequence.pad_sequences([tokens_list], maxlen=maxlen, padding='post')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "colab_type": "code",
    "id": "eUr4SQDveVb0",
    "outputId": "abafd831-63b1-4eee-e35a-323ce20e9fba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter question :  You are immortal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      " not quite but i can be perpetuated indefinitely end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter question :  what is mortal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      " an established system of political administration by which a nation state district etc is governed end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter question :  what is spider\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      " global organization promoting enviornmental activism end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter question :  what is spiderman\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      " a comic book story made into a movie end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter question :  who is spiderman\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      " a comic book story made into a movie end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter question :  who is the prime minister of india\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      " that is every few years end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter question :  who is the prime minister in 2020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      " it changes every few years end\n"
     ]
    }
   ],
   "source": [
    "enc_model , dec_model = make_inference_models()\n",
    "\n",
    "for _ in range(10):\n",
    "    states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n",
    "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
    "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "    while not stop_condition :\n",
    "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
    "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "        sampled_word = None\n",
    "        for word , index in tokenizer.word_index.items() :\n",
    "            if sampled_word_index == index :\n",
    "                decoded_translation += ' {}'.format( word )\n",
    "                sampled_word = word\n",
    "        \n",
    "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
    "            stop_condition = True\n",
    "            \n",
    "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "        states_values = [ h , c ] \n",
    "\n",
    "    print( decoded_translation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Chatbot_using_LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
